{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary libraries for data manipulation and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.special as sp\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "df = pd.read_csv(\"Datafil.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Warm-up\n",
    "The following tasks are designed to familiarize you with the dataset and prepare the data for use when building your predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) \n",
    "All scores in the dataframe are currently numbers between 0 and 10. Normalize these values in the dataframe so that they range between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(df):\n",
    "    # Normalize scores (from 6th column onwards)\n",
    "    for col in df.columns[5:]:\n",
    "        df[col] = df[col].apply(lambda x: x/10 if x == x else x)  # handle NaN values\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id      location  month  year        comp  heat  run 1  run 2  \\\n",
      "0      Berger  jacksonville      7  2022  prelim men   0.1   0.50   0.11   \n",
      "1        Papa  jacksonville      7  2022  prelim men   0.1   0.37   0.70   \n",
      "2     Pudwill  jacksonville      7  2022  prelim men   0.1   0.20   0.13   \n",
      "3      Shirai  jacksonville      7  2022  prelim men   0.1   0.79   0.70   \n",
      "4        Mota  jacksonville      7  2022  prelim men   0.1   0.38   0.40   \n",
      "..        ...           ...    ...   ...         ...   ...    ...    ...   \n",
      "92      Hoban     las vegas     10  2022   final men   0.1   0.62   0.88   \n",
      "93    Hoefler     las vegas     10  2022   final men   0.1   0.84   0.57   \n",
      "94      Eaton     las vegas     10  2022   final men   0.1   0.69   0.72   \n",
      "95     Joslin     las vegas     10  2022   final men   0.1   0.68   0.83   \n",
      "96  Ribeiro G     las vegas     10  2022   final men   0.1   0.85   0.30   \n",
      "\n",
      "    trick 1  trick 2  trick 3  trick 4  trick 5  trick 6  \n",
      "0      0.70     0.00     0.76     0.00      NaN      NaN  \n",
      "1      0.72     0.00     0.84     0.82      NaN      NaN  \n",
      "2      0.00     0.00     0.00     0.00      NaN      NaN  \n",
      "3      0.75     0.00     0.92     0.00      NaN      NaN  \n",
      "4      0.78     0.00     0.00     0.00      NaN      NaN  \n",
      "..      ...      ...      ...      ...      ...      ...  \n",
      "92     0.86     0.00     0.88     0.00     0.00     0.00  \n",
      "93     0.78     0.00     0.87     0.00     0.00     0.00  \n",
      "94     0.00     0.84     0.75     0.00      NaN      NaN  \n",
      "95     0.79     0.83     0.00     0.00     0.89     0.94  \n",
      "96     0.00     0.92     0.88     0.92     0.00     0.17  \n",
      "\n",
      "[97 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "normalize_scores(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "Create a histogram for all trick scores for tricks 1-4. \n",
    "- What do you observe? \n",
    "- Is there a particular value that appears more often than the others? \n",
    "- If so, how does this value compare to the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) here i create a histogram fr normalized data\n",
    "def plot_histograms(datafile):\n",
    "    # List of tricks\n",
    "    tricks = [\"trick 1\", \"trick 2\", \"trick 3\", \"trick 4\"]\n",
    "\n",
    "    # Plot histograms for each trick\n",
    "    for idx, trick in enumerate(tricks, 1):\n",
    "        plt.subplot(2, 2, idx)  # 2x2 grid of histograms\n",
    "        plt.hist(df[trick].dropna(), bins=20, alpha=0.7, color='blue')  # dropna() ensures NaN values are ignored\n",
    "        plt.title(f\"Histogram of {trick}\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Adjust layout to prevent overlaps and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histograms(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From our observations, the most common score for each trick is zero, by a significant margin. The majority of other scores fall within the 0.6 to 0.9 range, with a noticeable lack of scores between 0 and 0.6. This pattern suggests that contestants tend to attempt more challenging tricks, which typically result in either failure (yielding a score of zero) or a relatively high score. This behavior indicates a tendency to bypass tricks of easy to medium difficulty.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "For each trick (1-4), create a new column named 'make i' for \\(i=1,2,3,4\\). The value of 'make i' in a given row should be 1 if the skateboarder successfully landed trick \\(i\\) and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_make_columns(df):\n",
    "    # Loop through each trick column\n",
    "    for i in range(1, 5):\n",
    "        trick_column = f\"trick {i}\"\n",
    "        \n",
    "        # Assuming a trick is executed if its score > 0\n",
    "        df[f\"make {i}\"] = df[trick_column].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id      location  month  year        comp  heat  run 1  run 2  \\\n",
      "0      Berger  jacksonville      7  2022  prelim men   0.1   0.50   0.11   \n",
      "1        Papa  jacksonville      7  2022  prelim men   0.1   0.37   0.70   \n",
      "2     Pudwill  jacksonville      7  2022  prelim men   0.1   0.20   0.13   \n",
      "3      Shirai  jacksonville      7  2022  prelim men   0.1   0.79   0.70   \n",
      "4        Mota  jacksonville      7  2022  prelim men   0.1   0.38   0.40   \n",
      "..        ...           ...    ...   ...         ...   ...    ...    ...   \n",
      "92      Hoban     las vegas     10  2022   final men   0.1   0.62   0.88   \n",
      "93    Hoefler     las vegas     10  2022   final men   0.1   0.84   0.57   \n",
      "94      Eaton     las vegas     10  2022   final men   0.1   0.69   0.72   \n",
      "95     Joslin     las vegas     10  2022   final men   0.1   0.68   0.83   \n",
      "96  Ribeiro G     las vegas     10  2022   final men   0.1   0.85   0.30   \n",
      "\n",
      "    trick 1  trick 2  trick 3  trick 4  trick 5  trick 6  make 1  make 2  \\\n",
      "0      0.70     0.00     0.76     0.00      NaN      NaN       1       0   \n",
      "1      0.72     0.00     0.84     0.82      NaN      NaN       1       0   \n",
      "2      0.00     0.00     0.00     0.00      NaN      NaN       0       0   \n",
      "3      0.75     0.00     0.92     0.00      NaN      NaN       1       0   \n",
      "4      0.78     0.00     0.00     0.00      NaN      NaN       1       0   \n",
      "..      ...      ...      ...      ...      ...      ...     ...     ...   \n",
      "92     0.86     0.00     0.88     0.00     0.00     0.00       1       0   \n",
      "93     0.78     0.00     0.87     0.00     0.00     0.00       1       0   \n",
      "94     0.00     0.84     0.75     0.00      NaN      NaN       0       1   \n",
      "95     0.79     0.83     0.00     0.00     0.89     0.94       1       1   \n",
      "96     0.00     0.92     0.88     0.92     0.00     0.17       0       1   \n",
      "\n",
      "    make 3  make 4  \n",
      "0        1       0  \n",
      "1        1       1  \n",
      "2        0       0  \n",
      "3        1       0  \n",
      "4        0       0  \n",
      "..     ...     ...  \n",
      "92       1       0  \n",
      "93       1       0  \n",
      "94       1       0  \n",
      "95       0       0  \n",
      "96       1       1  \n",
      "\n",
      "[97 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "add_make_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\n",
    "For each skateboarder, estimate the probability that a trick receives a score greater than 0.6, given that the skateboarder successfully lands the trick. \n",
    "- What is the probability that the skateboarder fails to land a particular trick? \n",
    "- What observations can you make? Relate your findings to your observations in part (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Given that they make a trick estimate the probability of them getting a score that's higher than 0.6\n",
    "def estimate_probabilities(df):\n",
    "    # Here we group by skateboarder's name.\n",
    "    # This is becouse I want to have only one row for each skateboarder.\n",
    "    grouped_df = df.groupby('id')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, group in grouped_df:\n",
    "        # Number of tricks successfully landed for all locations\n",
    "        successful_tricks = group[[f\"trick {i}\" for i in range(1, 6)]].applymap(lambda x: 1 if x > 0 else 0).sum().sum()\n",
    "        # For every element (score) in the trick columns, this applies a function that converts it to 1 if it's greater than 0.\n",
    "        # Then it sums all the 1s in the dataframe.\n",
    "        # Then it sums all the 1s in the resulting series.\n",
    "        # This gives us the total number of tricks successfully landed for all locations.\n",
    "        # Note that this is not the same as the total number of tricks successfully landed for each location.\n",
    "        # For example, if a skateboarder landed 3 tricks in location 1 and 2 tricks in location 2, this will return 5.\n",
    "        \n",
    "        # Number of tricks with score >= 0.6 across all locations\n",
    "        tricks_score_more_than_06 = group[[f\"trick {i}\" for i in range(1, 6)]].applymap(lambda x: 1 if x >= 0.6 else 0).sum().sum()\n",
    "        # Same as above, but for tricks with score >= 0.6\n",
    "\n",
    "        # Probability that a trick receives a score greater than 0.6 given the trick was landed\n",
    "        prob_success_given_landed = tricks_score_more_than_06 / successful_tricks if successful_tricks > 0 else 0\n",
    "        # If the skateboarder didn't land any tricks, we set the probability to 0.\n",
    "        # Otherwise, we divide the number of tricks with score >= 0.6 by the total number of tricks successfully landed.\n",
    "        # This gives us the probability that a trick receives a score greater than 0.6 given the trick was landed.\n",
    "        \n",
    "        # Probability that the skateboarder fails to land a trick\n",
    "        total_tricks = group[[f\"trick {i}\" for i in range(1, 6)]].count().sum()\n",
    "        failed_tricks = group[[f\"trick {i}\" for i in range(1, 6)]].applymap(lambda x: 1 if x == 0 else 0).sum().sum()\n",
    "        prob_failure = failed_tricks / total_tricks\n",
    "        # Same as above, but for tricks with score = 0.\n",
    "        # This gives us the probability that the skateboarder fails to land a trick.\n",
    "        # Note that this is not the same as the probability that the skateboarder fails to land a trick given the trick was landed.\n",
    "        # For example, if a skateboarder landed 3 tricks in location 1 and 2 tricks in location 2, this will return 0.4.\n",
    "        \n",
    "        results.append((name, prob_success_given_landed, prob_failure))\n",
    "    \n",
    "    for name, success_given_landed, failure in results:\n",
    "        print(f\"Skateboarder {name}: P(Score > 0.6 | Landed) = {success_given_landed:.2f}, P(Failure) = {failure:.2f}\")\n",
    "    \n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skateboarder Berger: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.83\n",
      "Skateboarder Decenzo: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.59\n",
      "Skateboarder Eaton: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.38\n",
      "Skateboarder Foy: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Fynn: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Gustavo: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.60\n",
      "Skateboarder Hoban: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.62\n",
      "Skateboarder Hoefler: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.59\n",
      "Skateboarder Horigome: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Huston: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.62\n",
      "Skateboarder Jordan: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.60\n",
      "Skateboarder Joslin: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.55\n",
      "Skateboarder Majerus: P(Score > 0.6 | Landed) = 0.33, P(Failure) = 0.62\n",
      "Skateboarder McClung: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 0.75\n",
      "Skateboarder Midler: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Milou: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Mota: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Oliveira: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.58\n",
      "Skateboarder Oâ€™neill: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Papa: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.56\n",
      "Skateboarder Pudwill: P(Score > 0.6 | Landed) = 0.33, P(Failure) = 0.75\n",
      "Skateboarder Ribeiro C: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Ribeiro G: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Rodriguez: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Santiago: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 0.92\n",
      "Skateboarder Shirai: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.62\n",
      "Skateboarder Silvas: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.62\n",
      "Skateboarder Suciu: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.38\n",
      "Skateboarder Wair: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Wright: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n"
     ]
    }
   ],
   "source": [
    "#Pleas note that this is for all tricks!\n",
    "estimate_probabilities(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here, I will add a modified version of this code that handles each trick separately!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_probabilities_by_individual_trick(df):\n",
    "    # Group by skateboarder's name to get each skateboarder's data across all locations\n",
    "    grouped_df = df.groupby('id')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, group in grouped_df:\n",
    "        for i in range(1, 6):  # Iterate through each trick\n",
    "            trick_col = f\"trick {i}\"\n",
    "\n",
    "            # Number of times this specific trick was landed by the skateboarder across all locations\n",
    "            successful_tricks = group[trick_col].apply(lambda x: 1 if x > 0 else 0).sum()\n",
    "\n",
    "            # Number of times this specific trick got a score >= 0.6 by the skateboarder across all locations\n",
    "            tricks_score_more_than_06 = group[trick_col].apply(lambda x: 1 if x >= 0.6 else 0).sum()\n",
    "\n",
    "            # Probability that this trick receives a score greater than 0.6 given the trick was landed\n",
    "            prob_success_given_landed = tricks_score_more_than_06 / successful_tricks if successful_tricks > 0 else 0\n",
    "\n",
    "            # Total attempts of this specific trick by the skateboarder across all locations\n",
    "            total_tricks = group[trick_col].count()\n",
    "\n",
    "            # Number of times this specific trick failed (scored 0) by the skateboarder across all locations\n",
    "            failed_tricks = group[trick_col].apply(lambda x: 1 if x == 0 else 0).sum()\n",
    "\n",
    "            # Probability that the skateboarder fails to land this trick\n",
    "            prob_failure = failed_tricks / total_tricks\n",
    "\n",
    "            results.append((name, trick_col, prob_success_given_landed, prob_failure))\n",
    "\n",
    "    for name, trick, success_given_landed, failure in results:\n",
    "        print(f\"Skateboarder {name} for {trick}: P(Score > 0.6 | Landed) = {success_given_landed:.2f}, P(Failure) = {failure:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skateboarder Berger for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Berger for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Berger for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Berger for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Berger for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Decenzo for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.25\n",
      "Skateboarder Decenzo for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Decenzo for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.25\n",
      "Skateboarder Decenzo for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Decenzo for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Eaton for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Eaton for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Eaton for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Eaton for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Eaton for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Foy for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Foy for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Foy for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Foy for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Foy for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Fynn for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Fynn for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Fynn for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Fynn for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Fynn for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Gustavo for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.20\n",
      "Skateboarder Gustavo for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.80\n",
      "Skateboarder Gustavo for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.40\n",
      "Skateboarder Gustavo for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Gustavo for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Hoban for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.20\n",
      "Skateboarder Hoban for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.40\n",
      "Skateboarder Hoban for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.80\n",
      "Skateboarder Hoban for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Hoban for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Hoefler for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.25\n",
      "Skateboarder Hoefler for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Hoefler for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Hoefler for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Hoefler for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Horigome for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Horigome for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Horigome for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Horigome for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Horigome for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Huston for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Huston for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Huston for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Huston for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Huston for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Jordan for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.60\n",
      "Skateboarder Jordan for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Jordan for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.40\n",
      "Skateboarder Jordan for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.40\n",
      "Skateboarder Jordan for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Joslin for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.40\n",
      "Skateboarder Joslin for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.20\n",
      "Skateboarder Joslin for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.60\n",
      "Skateboarder Joslin for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Joslin for trick 5: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Majerus for trick 1: P(Score > 0.6 | Landed) = 0.50, P(Failure) = 0.00\n",
      "Skateboarder Majerus for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Majerus for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Majerus for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 0.50\n",
      "Skateboarder Majerus for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder McClung for trick 1: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 0.00\n",
      "Skateboarder McClung for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder McClung for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder McClung for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder McClung for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Midler for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Midler for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Midler for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Midler for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Midler for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Milou for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.20\n",
      "Skateboarder Milou for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.40\n",
      "Skateboarder Milou for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.80\n",
      "Skateboarder Milou for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.80\n",
      "Skateboarder Milou for trick 5: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Mota for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Mota for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Mota for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Mota for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Mota for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Oliveira for trick 1: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Oliveira for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Oliveira for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Oliveira for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Oliveira for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Oâ€™neill for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Oâ€™neill for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Oâ€™neill for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Oâ€™neill for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Oâ€™neill for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Papa for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.25\n",
      "Skateboarder Papa for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Papa for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.25\n",
      "Skateboarder Papa for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.75\n",
      "Skateboarder Papa for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Pudwill for trick 1: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 0.67\n",
      "Skateboarder Pudwill for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Pudwill for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Pudwill for trick 4: P(Score > 0.6 | Landed) = 0.50, P(Failure) = 0.33\n",
      "Skateboarder Pudwill for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Ribeiro C for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Ribeiro C for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Ribeiro C for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Ribeiro C for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Ribeiro C for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Ribeiro G for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.67\n",
      "Skateboarder Ribeiro G for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Ribeiro G for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.33\n",
      "Skateboarder Ribeiro G for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Ribeiro G for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Rodriguez for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Rodriguez for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Rodriguez for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Rodriguez for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Rodriguez for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Santiago for trick 1: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 0.67\n",
      "Skateboarder Santiago for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Santiago for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Santiago for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Santiago for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Shirai for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.40\n",
      "Skateboarder Shirai for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.60\n",
      "Skateboarder Shirai for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.60\n",
      "Skateboarder Shirai for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.80\n",
      "Skateboarder Shirai for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Silvas for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Silvas for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Silvas for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Silvas for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Silvas for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Suciu for trick 1: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Suciu for trick 2: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Suciu for trick 3: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Suciu for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.50\n",
      "Skateboarder Suciu for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Wair for trick 1: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Wair for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Wair for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Wair for trick 4: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Wair for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n",
      "Skateboarder Wright for trick 1: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Wright for trick 2: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Wright for trick 3: P(Score > 0.6 | Landed) = 1.00, P(Failure) = 0.00\n",
      "Skateboarder Wright for trick 4: P(Score > 0.6 | Landed) = 0.00, P(Failure) = 1.00\n",
      "Skateboarder Wright for trick 5: P(Score > 0.6 | Landed) = 0.00, P(Failure) = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villi\\AppData\\Local\\Temp\\ipykernel_23384\\417097349.py:27: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  prob_failure = failed_tricks / total_tricks\n"
     ]
    }
   ],
   "source": [
    "estimate_probabilities_by_individual_trick(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) \n",
    "Create a scatter plot for run score 1 versus run score 2. \n",
    "\n",
    "- Do you see any clear correlation from the diagram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def estimate_probabilities_by_individual_trick_row(df):\n",
    "    # Group by skateboarder's name to get each skateboarder's data across all locations\n",
    "    grouped_df = df.groupby('id')\n",
    "\n",
    "    # Create a dictionary to store results\n",
    "    results_dict = {}\n",
    "\n",
    "    for name, group in grouped_df:\n",
    "        # Create a sub-dictionary for each skateboarder\n",
    "        skateboarder_data = {}\n",
    "        \n",
    "        for i in range(1, 6):  # Iterate through each trick\n",
    "            trick_col = f\"trick {i}\"\n",
    "\n",
    "            # Number of times this specific trick was landed by the skateboarder across all locations\n",
    "            successful_tricks = group[trick_col].apply(lambda x: 1 if x > 0 else 0).sum()\n",
    "\n",
    "            # Number of times this specific trick got a score >= 0.6 by the skateboarder across all locations\n",
    "            tricks_score_more_than_06 = group[trick_col].apply(lambda x: 1 if x >= 0.6 else 0).sum()\n",
    "\n",
    "            # Probability that this trick receives a score greater than 0.6 given the trick was landed\n",
    "            prob_success_given_landed = tricks_score_more_than_06 / successful_tricks if successful_tricks > 0 else 0\n",
    "\n",
    "            # Total attempts of this specific trick by the skateboarder across all locations\n",
    "            total_tricks = group[trick_col].count()\n",
    "\n",
    "            # Number of times this specific trick failed (scored 0) by the skateboarder across all locations\n",
    "            failed_tricks = group[trick_col].apply(lambda x: 1 if x == 0 else 0).sum()\n",
    "\n",
    "            # Probability that the skateboarder fails to land this trick\n",
    "            prob_failure = failed_tricks / total_tricks\n",
    "\n",
    "            # Store the results in the sub-dictionary\n",
    "            skateboarder_data[f\"{trick_col} P(Score > 0.6 | Landed)\"] = prob_success_given_landed\n",
    "            skateboarder_data[f\"{trick_col} P(Failure)\"] = prob_failure\n",
    "        \n",
    "        # Add the sub-dictionary to the main dictionary with skateboarder's name as the key\n",
    "        results_dict[name] = skateboarder_data\n",
    "\n",
    "    # Convert the dictionary to a DataFrame and return it\n",
    "    results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    return results_df\n",
    "\n",
    "# Assuming you have a dataframe `df`\n",
    "# You can call the function and get the results in a DataFrame format\n",
    "# results_df = estimate_probabilities_by_individual_trick(df)\n",
    "# print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           trick 1 P(Score > 0.6 | Landed)  trick 1 P(Failure)  \\\n",
      "Berger                                 1.0            0.666667   \n",
      "Decenzo                                1.0            0.250000   \n",
      "Eaton                                  1.0            0.500000   \n",
      "Foy                                    1.0            0.333333   \n",
      "Fynn                                   1.0            0.666667   \n",
      "Gustavo                                1.0            0.200000   \n",
      "Hoban                                  1.0            0.200000   \n",
      "Hoefler                                1.0            0.250000   \n",
      "Horigome                               1.0            0.000000   \n",
      "Huston                                 1.0            0.500000   \n",
      "Jordan                                 1.0            0.600000   \n",
      "Joslin                                 1.0            0.400000   \n",
      "Majerus                                0.5            0.000000   \n",
      "McClung                                0.0            0.000000   \n",
      "Midler                                 1.0            0.666667   \n",
      "Milou                                  1.0            0.200000   \n",
      "Mota                                   1.0            0.333333   \n",
      "Oliveira                               0.0            1.000000   \n",
      "Oâ€™neill                                1.0            0.333333   \n",
      "Papa                                   1.0            0.250000   \n",
      "Pudwill                                0.0            0.666667   \n",
      "Ribeiro C                              1.0            0.000000   \n",
      "Ribeiro G                              1.0            0.666667   \n",
      "Rodriguez                              1.0            0.000000   \n",
      "Santiago                               0.0            0.666667   \n",
      "Shirai                                 1.0            0.400000   \n",
      "Silvas                                 1.0            0.000000   \n",
      "Suciu                                  1.0            0.000000   \n",
      "Wair                                   0.0            1.000000   \n",
      "Wright                                 0.0            1.000000   \n",
      "\n",
      "           trick 2 P(Score > 0.6 | Landed)  trick 2 P(Failure)  \\\n",
      "Berger                                 0.0            1.000000   \n",
      "Decenzo                                1.0            0.750000   \n",
      "Eaton                                  1.0            0.000000   \n",
      "Foy                                    1.0            0.333333   \n",
      "Fynn                                   1.0            0.000000   \n",
      "Gustavo                                1.0            0.800000   \n",
      "Hoban                                  1.0            0.400000   \n",
      "Hoefler                                1.0            0.750000   \n",
      "Horigome                               0.0            1.000000   \n",
      "Huston                                 1.0            0.500000   \n",
      "Jordan                                 0.0            1.000000   \n",
      "Joslin                                 1.0            0.200000   \n",
      "Majerus                                0.0            1.000000   \n",
      "McClung                                0.0            1.000000   \n",
      "Midler                                 1.0            0.666667   \n",
      "Milou                                  1.0            0.400000   \n",
      "Mota                                   1.0            0.666667   \n",
      "Oliveira                               1.0            0.666667   \n",
      "Oâ€™neill                                0.0            1.000000   \n",
      "Papa                                   0.0            1.000000   \n",
      "Pudwill                                0.0            1.000000   \n",
      "Ribeiro C                              0.0            1.000000   \n",
      "Ribeiro G                              1.0            0.333333   \n",
      "Rodriguez                              0.0            1.000000   \n",
      "Santiago                               0.0            1.000000   \n",
      "Shirai                                 1.0            0.600000   \n",
      "Silvas                                 1.0            0.500000   \n",
      "Suciu                                  1.0            0.000000   \n",
      "Wair                                   0.0            1.000000   \n",
      "Wright                                 0.0            1.000000   \n",
      "\n",
      "           trick 3 P(Score > 0.6 | Landed)  trick 3 P(Failure)  \\\n",
      "Berger                                 1.0            0.666667   \n",
      "Decenzo                                1.0            0.250000   \n",
      "Eaton                                  1.0            0.000000   \n",
      "Foy                                    1.0            0.333333   \n",
      "Fynn                                   1.0            0.666667   \n",
      "Gustavo                                1.0            0.400000   \n",
      "Hoban                                  1.0            0.800000   \n",
      "Hoefler                                1.0            0.500000   \n",
      "Horigome                               1.0            0.000000   \n",
      "Huston                                 0.0            1.000000   \n",
      "Jordan                                 1.0            0.400000   \n",
      "Joslin                                 1.0            0.600000   \n",
      "Majerus                                0.0            1.000000   \n",
      "McClung                                0.0            1.000000   \n",
      "Midler                                 1.0            0.666667   \n",
      "Milou                                  1.0            0.800000   \n",
      "Mota                                   0.0            1.000000   \n",
      "Oliveira                               1.0            0.333333   \n",
      "Oâ€™neill                                1.0            0.666667   \n",
      "Papa                                   1.0            0.250000   \n",
      "Pudwill                                0.0            1.000000   \n",
      "Ribeiro C                              0.0            1.000000   \n",
      "Ribeiro G                              1.0            0.333333   \n",
      "Rodriguez                              1.0            0.000000   \n",
      "Santiago                               0.0            1.000000   \n",
      "Shirai                                 1.0            0.600000   \n",
      "Silvas                                 0.0            1.000000   \n",
      "Suciu                                  0.0            1.000000   \n",
      "Wair                                   1.0            0.000000   \n",
      "Wright                                 1.0            0.000000   \n",
      "\n",
      "           trick 4 P(Score > 0.6 | Landed)  trick 4 P(Failure)  \\\n",
      "Berger                                 0.0            1.000000   \n",
      "Decenzo                                0.0            1.000000   \n",
      "Eaton                                  0.0            1.000000   \n",
      "Foy                                    0.0            1.000000   \n",
      "Fynn                                   1.0            0.666667   \n",
      "Gustavo                                0.0            1.000000   \n",
      "Hoban                                  0.0            1.000000   \n",
      "Hoefler                                1.0            0.750000   \n",
      "Horigome                               1.0            0.750000   \n",
      "Huston                                 1.0            0.500000   \n",
      "Jordan                                 1.0            0.400000   \n",
      "Joslin                                 0.0            1.000000   \n",
      "Majerus                                0.0            0.500000   \n",
      "McClung                                0.0            1.000000   \n",
      "Midler                                 1.0            0.666667   \n",
      "Milou                                  1.0            0.800000   \n",
      "Mota                                   0.0            1.000000   \n",
      "Oliveira                               1.0            0.333333   \n",
      "Oâ€™neill                                0.0            1.000000   \n",
      "Papa                                   1.0            0.750000   \n",
      "Pudwill                                0.5            0.333333   \n",
      "Ribeiro C                              0.0            1.000000   \n",
      "Ribeiro G                              1.0            0.500000   \n",
      "Rodriguez                              0.0            1.000000   \n",
      "Santiago                               0.0            1.000000   \n",
      "Shirai                                 1.0            0.800000   \n",
      "Silvas                                 0.0            1.000000   \n",
      "Suciu                                  1.0            0.500000   \n",
      "Wair                                   1.0            0.000000   \n",
      "Wright                                 0.0            1.000000   \n",
      "\n",
      "           trick 5 P(Score > 0.6 | Landed)  trick 5 P(Failure)  \n",
      "Berger                                 0.0                 NaN  \n",
      "Decenzo                                0.0                 1.0  \n",
      "Eaton                                  0.0                 NaN  \n",
      "Foy                                    0.0                 NaN  \n",
      "Fynn                                   0.0                 NaN  \n",
      "Gustavo                                0.0                 NaN  \n",
      "Hoban                                  0.0                 1.0  \n",
      "Hoefler                                0.0                 1.0  \n",
      "Horigome                               0.0                 1.0  \n",
      "Huston                                 0.0                 NaN  \n",
      "Jordan                                 0.0                 NaN  \n",
      "Joslin                                 1.0                 0.5  \n",
      "Majerus                                0.0                 NaN  \n",
      "McClung                                0.0                 NaN  \n",
      "Midler                                 0.0                 NaN  \n",
      "Milou                                  1.0                 0.0  \n",
      "Mota                                   0.0                 NaN  \n",
      "Oliveira                               0.0                 NaN  \n",
      "Oâ€™neill                                0.0                 NaN  \n",
      "Papa                                   0.0                 NaN  \n",
      "Pudwill                                0.0                 NaN  \n",
      "Ribeiro C                              0.0                 NaN  \n",
      "Ribeiro G                              0.0                 1.0  \n",
      "Rodriguez                              0.0                 NaN  \n",
      "Santiago                               0.0                 NaN  \n",
      "Shirai                                 0.0                 1.0  \n",
      "Silvas                                 0.0                 NaN  \n",
      "Suciu                                  0.0                 NaN  \n",
      "Wair                                   0.0                 NaN  \n",
      "Wright                                 0.0                 NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villi\\AppData\\Local\\Temp\\ipykernel_23384\\803681420.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  prob_failure = failed_tricks / total_tricks\n"
     ]
    }
   ],
   "source": [
    "print(estimate_probabilities_by_individual_trick_row(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmc0lEQVR4nO3deXxU5dn/8e9MyEJCAkjYJAlB1kRBSFgERbqwVlGoFoRWEEStGtGiVSiySRHcqOLGU5XKz9YHFJW2SFlEaGVRWgwUmrApmBBkCRQSg5CEOb8/zjOByTaZZDIzZ+bzfr14HXLOmZl7ztxzZq4593XdNsMwDAEAAAAAqmT3dwMAAAAAINAROAEAAACAGwROAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsETgAAAADgBoETAAAAALhB4AQAAAAAbhA4AUCAOnz4sGw2m95++21/NwUAgJBH4ATA53bv3q3bb79dbdu2VVRUlNq0aaNBgwbp5ZdfrrfHfPfdd/Xiiy9WWH/06FHNnj1bO3furLfHLm/Tpk2y2Wxl/8LDw3XVVVdp3Lhx+vrrr73yGFu3btXs2bN15swZr9wf6m779u164IEHlJ6ervDwcNlsNn83CT704YcfavTo0brqqqsUHR2tzp0769FHH+U9ClgIgRMAn9q6dat69uypXbt26Z577tErr7yiSZMmyW6366WXXqq3x60ucJozZ45PAyenyZMn65133tHvf/973XTTTVq+fLl69eqlo0eP1vm+t27dqjlz5vClLICsXr1ab775pmw2m6666ip/Nwc+du+99yo7O1u/+MUvtGjRIg0dOlSvvPKK+vbtq++//97fzQNQAw383QAAoWXevHlq3Lix/vnPf6pJkyYu206cOOGfRtWDoqIixcTEVLtP//79dfvtt0uSJkyYoE6dOmny5MlaunSppk2b5otmeszhcKi4uFhRUVH+borPGIah8+fPq2HDhnW6n/vvv19PPPGEGjZsqIyMDO3fv99LLfQdbx0Lqzl37pyio6PrdB8rVqzQD37wA5d16enpGj9+vP70pz9p0qRJdbp/APWPK04AfOqrr77S1VdfXSFokqQWLVpUWPfHP/5RvXv3VnR0tJo2baobb7xR69atK9v+5z//WTfddJOuvPJKRUZGqn379po7d64uXrxYts8PfvADffzxx/rmm2/KhsclJydr06ZN6tWrlyQzcHFuuzyn6IsvvtDQoUPVuHFjRUdHa8CAAdqyZYtLG2fPni2bzaasrCyNHTtWTZs21Q033ODxsfnRj34kSTp06FC1+3366afq37+/YmJi1KRJE916663Kzs52ac+vf/1rSVK7du3Kntfhw4clSfn5+dq7d6/OnTvntk02m00ZGRn605/+pKuvvlqRkZFas2ZN2XDDTZs2uexfWV7WXXfdpUaNGikvL08jRoxQo0aN1Lx5cz322GMur1NV/vWvf2nIkCGKj49Xw4YN1a5dO02cONFlH4fDoZdeekldu3ZVVFSUmjdvrqFDh+pf//pX2T6lpaWaO3eu2rdvr8jISCUnJ+s3v/mNLly44HJfycnJuvnmm7V27Vr17NlTDRs21P/8z/9Iks6cOaNHHnlEiYmJioyMVIcOHfTMM8/I4XC4fR4tW7asdcBxzTXX6Ic//GGF9Q6HQ23atCkLwCVp2bJlSk9PV2xsrOLi4tS1a9daX82t6lhUl39ns9k0e/bssr+d74+DBw/qrrvuUpMmTdS4cWNNmDChRn3wwIEDuu2229SqVStFRUUpISFBd9xxh86ePeuyn7tzhSS99tprZf34yiuv1IMPPljhquwPfvADXXPNNdqxY4duvPFGRUdH6ze/+Y0k6cKFC5o1a5Y6dOigyMhIJSYm6vHHH6/QhypTPmiSpJEjR0qSy/sXQODiihMAn2rbtq22bdumPXv26Jprrql23zlz5mj27Nnq16+fnnrqKUVEROiLL77Qp59+qsGDB0uS3n77bTVq1EhTpkxRo0aN9Omnn2rmzJkqKCjQc889J0maPn26zp49qyNHjuh3v/udJKlRo0ZKSUnRU089pZkzZ+ree+9V//79JUn9+vWTZAYow4YNU3p6umbNmiW73a4//OEP+tGPfqTPPvtMvXv3dmnvz372M3Xs2FFPP/20DMPw+Nh89dVXkqRmzZpVuc8nn3yiYcOG6aqrrtLs2bP1/fff6+WXX9b111+vL7/8UsnJyfrpT3+q/fv363//93/1u9/9TvHx8ZKk5s2bS5JeeeUVzZkzRxs3bqz0y1x5n376qd577z1lZGQoPj5eycnJHg8BvHjxooYMGaI+ffro+eef1yeffKIXXnhB7du31/3331/l7U6cOKHBgwerefPmmjp1qpo0aaLDhw/rww8/dNnv7rvv1ttvv61hw4Zp0qRJKi0t1WeffabPP/9cPXv2lCRNmjRJS5cu1e23365HH31UX3zxhebPn6/s7Gx99NFHLve3b98+jRkzRvfdd5/uuecede7cWefOndOAAQOUl5en++67T0lJSdq6daumTZumb7/9ttKhoN4yevRozZ49W8eOHVOrVq3K1m/evFlHjx7VHXfcIUlav369xowZox//+Md65plnJJlfyrds2aKHH364Vo9d2bGojVGjRqldu3aaP3++vvzyS7355ptq0aJFWTsrU1xcrCFDhujChQt66KGH1KpVK+Xl5WnVqlU6c+aMGjduLKlm54rZs2drzpw5GjhwoO6//37t27dPr7/+uv75z39qy5YtCg8PL3vcU6dOadiwYbrjjjv0i1/8Qi1btpTD4dAtt9yizZs3695771VKSop2796t3/3ud9q/f79Wrlzp8TE5duyYJJW9RwEEOAMAfGjdunVGWFiYERYWZvTt29d4/PHHjbVr1xrFxcUu+x04cMCw2+3GyJEjjYsXL7psczgcZf8/d+5chce47777jOjoaOP8+fNl62666Sajbdu2Ffb95z//aUgy/vCHP1R4jI4dOxpDhgyp8Hjt2rUzBg0aVLZu1qxZhiRjzJgxNToGGzduNCQZS5YsMU6ePGkcPXrU+Pjjj43k5GTDZrMZ//znPw3DMIxDhw5VaFv37t2NFi1aGKdOnSpbt2vXLsNutxvjxo0rW/fcc88ZkoxDhw5VeHxnezdu3Oi2rZIMu91u/Oc//6n0OZS/j8raPH78eEOS8dRTT7ns26NHDyM9Pb3ax//oo48MSWXHpDKffvqpIcmYPHlyhW3O127nzp2GJGPSpEku2x977DFDkvHpp5+WrWvbtq0hyVizZo3LvnPnzjViYmKM/fv3u6yfOnWqERYWZuTk5FT7XC734IMPGp58BO/bt8+QZLz88ssu6x944AGjUaNGZe+Dhx9+2IiLizNKS0trfN/VqepYVPY6O0kyZs2aVfa3s79NnDjRZb+RI0cazZo1q/bxMzMzDUnG+++/X+U+NTlXnDhxwoiIiDAGDx7sss8rr7xS9l50GjBggCHJWLx4sct9vfPOO4bdbjc+++wzl/WLFy82JBlbtmyp9rlU5u677zbCwsIq9CkAgYmhegB8atCgQdq2bZtuueUW7dq1S88++6yGDBmiNm3a6C9/+UvZfitXrpTD4dDMmTNlt7ueqi6vRnb50KfCwkLl5+erf//+OnfunPbu3Vvrdu7cuVMHDhzQ2LFjderUKeXn5ys/P19FRUX68Y9/rH/84x8Vhmf98pe/9OgxJk6cqObNm+vKK6/UTTfdpKKiIi1durTsCkl53377rXbu3Km77rpLV1xxRdn6bt26adCgQVq9enWNHnf27NkyDKNGV5skacCAAUpNTa3RvtUpf3z69+/vtoqgc0jnqlWrVFJSUuk+H3zwgWw2m2bNmlVhm7OvOI/NlClTXLY/+uijkqSPP/7YZX27du00ZMgQl3Xvv/+++vfvr6ZNm5b1h/z8fA0cOFAXL17UP/7xj2qfS1106tRJ3bt31/Lly8vWXbx4UStWrNDw4cPL3gdNmjRRUVGR1q9f77XHruxY1EZlr/+pU6dUUFBQ5W2cV5TWrl1b5bC+mpwrPvnkExUXF+uRRx5x2eeee+5RXFxchdc/MjJSEyZMcFn3/vvvKyUlRV26dHF5/Z1DbDdu3Fjd06/g3Xff1VtvvaVHH31UHTt29Oi2APyDwAmAz/Xq1Usffvih/vvf/2r79u2aNm2aCgsLdfvttysrK0uSOWzNbre7/cL+n//8RyNHjlTjxo0VFxen5s2b6xe/+IUkVciB8MSBAwckSePHj1fz5s1d/r355pu6cOFChftv166dR48xc+ZMrV+/Xp9++qn+/e9/6+jRo7rzzjur3P+bb76RpEqHSqWkpJQFdt7m6fOqjDPv6HJNmzbVf//732pvN2DAAN12222aM2eO4uPjdeutt+oPf/iDS07JV199pSuvvNIlmCzvm2++kd1uV4cOHVzWt2rVSk2aNCk7tk6VPecDBw5ozZo1FfrDwIEDJdV/cZPRo0dry5YtysvLk2SWtT9x4oRGjx5dts8DDzygTp06adiwYUpISNDEiRO1Zs2aOj2uN15/SUpKSnL5u2nTppJUbR9o166dpkyZojfffFPx8fEaMmSIXn31VZf3Xk3OFVW9dyIiInTVVVdVeP3btGmjiIgIl3UHDhzQf/7znwqvf6dOnSR59vp/9tlnuvvuuzVkyBDNmzevxrcD4F/kOAHwm4iICPXq1Uu9evVSp06dNGHCBL3//vuVXjmozJkzZzRgwADFxcXpqaeeUvv27RUVFaUvv/xSTzzxRI0S9qvivO1zzz2n7t27V7pPo0aNXP72NPG/a9euZV+6A1llz6uqOYiqKvYQFhZWq8e22WxasWKFPv/8c/31r3/V2rVrNXHiRL3wwgv6/PPPK7wGNbm/mqjsOTscDg0aNEiPP/54pbdxfoGuL6NHj9a0adP0/vvv65FHHtF7772nxo0ba+jQoWX7tGjRQjt37tTatWv1t7/9TX/729/0hz/8QePGjdPSpUtr9bjeeP2lqvuA4SYf8IUXXtBdd92lP//5z1q3bp0mT56s+fPn6/PPP1dCQkK1t62tql7/rl27auHChZXeJjExsUb3vWvXLt1yyy265pprtGLFCjVowFcxwCp4twIICM7had9++60kqX379nI4HMrKyqoycNm0aZNOnTqlDz/8UDfeeGPZ+sqq0lX1Ra+q9e3bt5ckxcXFBUxw07ZtW0lmsn55e/fuVXx8fFkJ9PqeXNV5taB8kYjyv9x7y3XXXafrrrtO8+bN07vvvquf//znWrZsmSZNmqT27dtr7dq1On36dJVXndq2bSuHw6EDBw4oJSWlbP3x48d15syZsmNbnfbt2+u7777zW39o166devfureXLlysjI0MffvihRowYocjISJf9IiIiNHz4cA0fPlwOh0MPPPCA/ud//kczZsyocMWttnz9+nft2lVdu3bVk08+qa1bt+r666/X4sWL9dvf/rZG54rL3zuXz6FVXFysQ4cO1eg1bd++vXbt2qUf//jHtX5/ffXVVxo6dKhatGih1atXexz4A/AvhuoB8KmNGzdW+guzMwfFOZRmxIgRstvteuqppypcOXLe3vkL9uX3V1xcrNdee63C/cfExFQ6dM8ZaJT/Apienq727dvr+eef13fffVfhdidPnqzyOdaX1q1bq3v37lq6dKlLe/fs2aN169bpJz/5Sdm6qp6X5Fk58qq0bdtWYWFhFfJ6Kjv2dfHf//63Qn9xfjl2Dte77bbbZBiG5syZU+H2zts6j035ynfOqwc33XST27aMGjVK27Zt09q1aytsO3PmjEpLS93eR12NHj1an3/+uZYsWaL8/HyXYXqSWQ3ucna7Xd26dZN06XiVlJRo7969ZT9S1EZcXJzi4+Pr/fUvKCiocFy7du0qu91e9nxqcq4YOHCgIiIitGjRIpf+9NZbb+ns2bM1fv3z8vL0xhtvVNj2/fffux0me+zYMQ0ePFh2u11r166tMHQVQODjihMAn3rooYd07tw5jRw5Ul26dFFxcbG2bt2q5cuXKzk5uSwhu0OHDpo+fbrmzp2r/v3766c//akiIyP1z3/+U1deeaXmz5+vfv36qWnTpho/frwmT54sm82md955p9LALD09XcuXL9eUKVPUq1cvNWrUSMOHD1f79u3VpEkTLV68WLGxsYqJiVGfPn3Url07vfnmmxo2bJiuvvpqTZgwQW3atFFeXp42btyouLg4/fWvf/X14dNzzz2nYcOGqW/fvrr77rvLypE3btzYZe6c9PR0SWYp9jvuuEPh4eEaPny4YmJiPC5HXpnGjRvrZz/7mV5++WXZbDa1b99eq1at8nqez9KlS/Xaa69p5MiRat++vQoLC/XGG28oLi6uLBj64Q9/qDvvvFOLFi3SgQMHNHToUDkcDn322Wf64Q9/qIyMDF177bUaP368fv/735cN8dy+fbuWLl2qESNGVDpHUnm//vWv9Ze//EU333yz7rrrLqWnp6uoqEi7d+/WihUrdPjw4WrLSn/zzTd65513JKlsfqnf/va3ksxAtLr8NqdRo0bpscce02OPPaYrrriiwpWSSZMm6fTp0/rRj36khIQEffPNN3r55ZfVvXv3sitteXl5SklJ0fjx4yudh6mmJk2apAULFmjSpEnq2bOn/vGPf3h9Ut9PP/1UGRkZ+tnPfqZOnTqptLRU77zzjsLCwnTbbbdJqtm5onnz5po2bZrmzJmjoUOH6pZbbtG+ffv02muvqVevXmV5kdW588479d577+mXv/ylNm7cqOuvv14XL17U3r179d5775XNdVWVoUOH6uuvv9bjjz+uzZs3a/PmzWXbWrZsqUGDBtX9gAGoX36q5gcgRP3tb38zJk6caHTp0sVo1KiRERERYXTo0MF46KGHjOPHj1fYf8mSJUaPHj2MyMhIo2nTpsaAAQOM9evXl23fsmWLcd111xkNGzY0rrzyyrLy5ipXKvu7774zxo4dazRp0sSQ5FKa/M9//rORmppqNGjQoEKJ5czMTOOnP/2p0axZMyMyMtJo27atMWrUKGPDhg1l+zjLLZ88ebJGx8BZyru6EsuGUXXJ508++cS4/vrrjYYNGxpxcXHG8OHDjaysrAq3nzt3rtGmTRvDbre7lCb3tBz5gw8+WOm2kydPGrfddpsRHR1tNG3a1LjvvvuMPXv2VFqOPCYmpsLtne2ozpdffmmMGTPGSEpKMiIjI40WLVoYN998s/Gvf/3LZb/S0lLjueeeM7p06WJEREQYzZs3N4YNG2bs2LGjbJ+SkhJjzpw5Rrt27Yzw8HAjMTHRmDZtmkvZesMwS3DfdNNNlbansLDQmDZtmtGhQwcjIiLCiI+PN/r162c8//zzFUrql+d83Sv7N2DAgGpve7nrr7++0tLqhmEYK1asMAYPHmy0aNHCiIiIMJKSkoz77rvP+Pbbb8v2cfar8ePHu32s6o7FuXPnjLvvvtto3LixERsba4waNco4ceJEleXIy78//vCHP1RZMt/p66+/NiZOnGi0b9/eiIqKMq644grjhz/8ofHJJ59U2NfducIwzPLjXbp0McLDw42WLVsa999/v/Hf//7XZZ8BAwYYV199daXtKS4uNp555hnj6quvLnuc9PR0Y86cOcbZs2erfB6GYVT52nv6+gPwH5th1GKWRgAAAAAIIeQ4AQAAAIAbBE4AAAAA4AaBEwAAAAC4QeAEAAAAAG4QOAEAAACAGwROAAAAAOBGyE2A63A4dPToUcXGxspms/m7OQAAAAD8xDAMFRYW6sorr5TdXv01pZALnI4eParExER/NwMAAABAgMjNzVVCQkK1+4Rc4BQbGyvJPDhxcXF+bg3qQ0lJidatW6fBgwcrPDzc380BqkV/hZXQX2El9FfUREFBgRITE8tihOqEXODkHJ4XFxdH4BSkSkpKFB0drbi4OE6UCHj0V1gJ/RVWQn+FJ2qSwkNxCAAAAABwg8AJAAAAANwgcAIAAAAANwicAAAAAMANAicAAAAAcIPACQAAAADcIHACAAAAADcInAAAAADADQInAAAAAHCDwAkAAAAA3CBwAgAAAAA3CJwAAAAAwA0CJwAAAABwo4G/GwAAAADA+hwOKSdHKiyUYmOlpCTJHkSXaQicAAAAANRJdrb00UfS3r3S+fNSVJTUpYs0cqSUkuLv1nkHgRMAAACAWsvOlhYtkvLzpcREKSZGKiqSMjOl3Fxp8uTgCJ6C6OIZAAAAAF9yOMwrTfn5UmqqFBcnhYWZy9RUc/3KleZ+VscVJwAA/CTY8wFqI1COSaC0Awh0OTnm8LzERMlmc91ms0kJCeYVqZwcKTnZL030GgInAAD8IBTyATwVKMckUNoBWEFhofk+iYmpfHtMjJSXZ+5ndQROAAD4WKjkA3giUI5JoLQDsIrYWPPHhaIic3heeUVF5vbYWN+3zdu46AwAgA+FUj5ATQXKMQmUdgBWkpRkXpHNzZUMw3WbYUhHjpg/NiQl+ad93kTgBACAD3mSDxAqAuWYBEo7ACux281hrPHxUlaWdPasVFpqLrOyzPUjRgRHjiBD9QAEFRK6EehCKR+gpgLlmPijHb46Z3FuRH1KSTGHsTpzA/PyzOF5aWlm0BQsw1sJnAAEDRK6YQWhlA9QU4FyTHzdDl+dszg3whdSUqTOnYM7QA+ipwIglDkTujMzzWEBnTuby8xMc312tr9bCJhCKR+gpgLlmPiyHb46Z3FuhC/Z7WbJ8a5dzWUwBU0SgROAIEBCN6wklPIBaipQjomv2uGrcxbnRsC7Qui0DCBYkdANq3HmA/ToIZ06Je3fby7T0kK33HWgHBNftMNX5yzOjYB3keMEryDpFP4UKInlgCdCIR/AU4FyTOq7Hb46Z3FuBLyLwAl1RtIp/C1QEssBTznzAXBJoByT+myHr85ZnBsB7wrh37XgDSSdIhAESmI5ANSEr85ZnBsB7yJwQq2RdIpAESiJ5QBQE746Z3FuBLyLoXqoNU+STgNh2AWCW6hMvgdYGfmwl/jqnOV8nA8+kL780hyeFxMjpadLP/0p50bAEwROqDWSThFoAiWxHEBF5MNW5MtzlvMHzvJD9gDUHIETao2kUwSiQEksB3CJMx82P98cpRATY35GZGaa+TehWoJdqv9z1uXHPjn50rHfudPMcQrlYw94it9hUWsknQIA3CEf1n849oB3ETih1kg6BQC4wySs/sOxB7yLr7Sok0CZ6R0AEJhqkg97/jz5sPWBY183Dod0+LC0e7e55MocyHFCnZGQDwCoCvmw/sOxrz2KmaAyfLWFVziTW7t2NZcETQAAiXxYf+LY146zoEZmppl20LmzuczMNNdnZ/u7hfAXvt4CAIB6Qz6s/3DsPUdBDVSHoXoAAKBeMUG1/1jx2JeWSp9/Lh0/LrVsKV13ndTAR99YPSmoUZMy8kz6HFwInAAAQL0jH9Z/rHTsV60yh8MdPCiVlEjh4VKHDmbwd/PN9f/4NSmokZdXs4Ia5EkFHwInAADgE0xQ7T9WOParVklPPGEOJWzRQoqOls6dM4cVPvGEuU99B0/eKqjBpM/BKQB/awAAAEAoKS01A42zZ6WrrjKDlgYNzOVVV5nrX37Z3K8+eaOgBnlSwYvACQAAAH71+efm8LwWLSoOIbTbpebNpQMHzP3qkzcKajDxcPBiqB4AIGCQSI1gQn+uuePHzZym6OjKt8fEmFdqjh+v/+Na14Ia3syTQmAhcAIABAQSqRFM6M+eadnSLARx7lzVuUXh4dL330sLFtT/ca1LQQ0mHg5eBE4AAL8jkRrBhP7sueuuM6vnZWVJjRq5BigOh3TypNS2rfTZZ9Lp0745rrUtqOHMk8rMNHOaLh+u58yTSktj4mEr4oIxAMCvSKRGMKE/106DBmbg07ix9PXXrrlFX39tHr/27c2gKdCPKxMPBy9eMgCAX5FIjWBCf669m2+WnnnGDITOnpW++cZcXn219Oij5j5WOa7OPKkePaRTp6T9+81lWhpXHK2MoXpAACOxGKGARGoEE/pz3dx8szR0qFk97/hxM/fpuuvMoGjtWmsdVytNPIyaIXACAhSJxQgVJFIjmNCf665BA+mGG1zXWfW4WmHiYdQcMS8QgJyJxZmZ5ljozp3NZWamuT47298tBLzHGxNOAoGC/lw/OK4IBAROQIAhsRihhkRqBBP6c/3guCIQMFQPCDCeJBZz+R/Boq4TTgL+UFUearD2Z3/n3QbrcYV1EDgBAYbEYoQqEqlhJe7yUIOtPwdK3m2wHVdYC4ETEGCsmgALeAOJ1LCCmk5wGyz9OdAm9A2W4wrrIT4HAgwJsAAQuEItDzXUni9QHQInIMCQAAsAgSvUJrgNtecLVIevXkAAYsZxAAhMNclDPX++5nmoDod0+LC0e7e5DLQrN1Z9vs5CFpK5DLTjCmsixwkIUCTAAkDg8WYeaqAUXKiOFZ+v83EOHpRuvVWaN0/q0CGwjiusia9gQABzJsB27WouCZoAwL+8lYdqlYnOrfZ8L3+cZs3Mdc2aBd5xhTXxNQwAAKCGvJGHaqWCC1Z6vuUfx3kVLDY28I4rrInACQAAwAN1zUO1WsEFqzxfqx1XWA85TgAAAB6qSx6qFSc6t8LzteJxhbUQOAEAANRCbSditepE54H+fK16XGEdDNUDAADwoVCb6NxXzzfUjit8j8AJAADAh0JtonNfPd/yj1NQYK4vKAjO4wrfY6geEOSckwAyFxQABA5nwQXnvEZ5eeYwsrQ088t9sM035Kvne/njHDxorjt9OniPK3zL74HTq6++queee07Hjh3Ttddeq5dfflm9e/eucv8XX3xRr7/+unJychQfH6/bb79d8+fPV1RUlA9bDViDFSZXBIBQFWoTnfvq+Tof59Ahac8eafp0qV274D2u8B2/Bk7Lly/XlClTtHjxYvXp00cvvviihgwZon379qlFixYV9n/33Xc1depULVmyRP369dP+/ft11113yWazaeHChX54BkDgck4CmJ9vlmaNiTETYzMzzfHfNSkhCwCoX7UtuGBVvnq+drsZlO3ZE9zBKHzLr91o4cKFuueeezRhwgSlpqZq8eLFio6O1pIlSyrdf+vWrbr++us1duxYJScna/DgwRozZoy2b9/u45YDgc1KkysCAABYgd+uOBUXF2vHjh2aNm1a2Tq73a6BAwdq27Ztld6mX79++uMf/6jt27erd+/e+vrrr7V69WrdeeedVT7OhQsXdOHChbK/C/4vU7CkpEQlJSVeejYIJM7XNZRf35wcc2x3crIZMJXXtq104IA5jIHqQv5Ff4WV0F9hJfRX1IQn/cNvgVN+fr4uXryoli1buqxv2bKl9u7dW+ltxo4dq/z8fN1www0yDEOlpaX65S9/qd/85jdVPs78+fM1Z86cCuvXrVun6Ojouj0JBLT169f7uwl+deut7vfZs8f8B/8L9f4Ka6G/wkror6jOuXPnaryv34tDeGLTpk16+umn9dprr6lPnz46ePCgHn74Yc2dO1czZsyo9DbTpk3TlClTyv4uKChQYmKiBg8erLjKZkeD5ZWUlGj9+vUaNGiQwsPD/d0cv8jJkebNk5o1q3yiv4ICs8rQ9OlccSpv3z5p1Spp//5LBTU6dZJuvtlMNvY2+iushP56ia/PFf5mxedLf0VNOEej1YTfAqf4+HiFhYXp+PHjLuuPHz+uVq1aVXqbGTNm6M4779SkSZMkSV27dlVRUZHuvfdeTZ8+XfZKMv8iIyMVGRlZYX14eDhvoiAXyq9xu3ZShw5mIYjUVMlmu7TNMKRvvjFLs1JlyFV2tvTqqxULauzYYR6z+iyoEcr9FdYT6v3Vn+cKf7D68w31/orqedI3/PaVKSIiQunp6dqwYUPZOofDoQ0bNqhv376V3ubcuXMVgqOw/0vgMMpPEQ2EsFCbXNEbKKgBoCZC7VwRas8XqI5fvzZNmTJFb7zxhpYuXars7Gzdf//9Kioq0oQJEyRJ48aNcykeMXz4cL3++utatmyZDh06pPXr12vGjBkaPnx4WQAFwOScBLBHD+nUKXN4xalT5pWmQP910B9ycsz5rhITXa/QSebfCQnmr645Ob5tl8MhHT4s7d5tLvlyAvhXoJ4r6kuoPV+gOn7NcRo9erROnjypmTNn6tixY+revbvWrFlTVjAiJyfH5QrTk08+KZvNpieffFJ5eXlq3ry5hg8frnnz5vnrKQABLdQmV6yLwkJz3H5MTOXbY2LMme4LC33XJiYwBgJPIJ4r6lOoPV+gOn4vDpGRkaGMjIxKt23atMnl7wYNGmjWrFmaNWuWD1oGBIdQm1yxtmJjzcCkqMgcglJeUZG5vbJiG/WBCYyBwBRo54r6FmrPF6gOvzsDgMwrcV26mEFJ+ZRJw5COHDEDFV9UISSnAAhcgXSu8IVQe75AdQicAECBVVCDnAIgcAXSucIXQu35AtWhmwPA/wmUgho1ySk4f56cAsBfAuVc4Suh9nyBqvg9xwkAAkkgFNQgpwAIfIFwrvClUHu+QGUInACgHH8X1HDmFFQ1gfGRI+YvveQUAP7l73OFr4Xa8wXK43cCAAgw5BQAABB4+NgFgABETgEAAIGFoXoAEKDIKQBQEw5H3c8T3rgPINgROAFAACOnAEB1srPNed/27jWrbUZFmTmSI0fW/Mq0N+4DCAUETgAAABaUnS0tWmROip2YaE5VUFRkFpbJza3ZsF5v3AcQKrgICwAAYDEOh3mVKD/frL4ZFyeFhZnL1FRz/cqV5n71eR9AKCFwAgAAqAcOh3T4sLR7t7n0ZgCSk2MOrUtMdJ2yQDL/Tkgwrybl5NTvfQChhKF6AAAAXlbfeUOFheb9xsRUvj0mRsrLM/erz/sAQglXnAAAALzImTeUmWnOu9a5s7nMzDTXZ2fX/TFiY81grKio8u1FReb22Nj6vQ8glBA4AQAAeImv8oaSkswrWLm5kmG4bjMM6cgR88pWUlL93gcQSgicAAAAvMRXeUN2uznsLz5eysqSzp6VSkvNZVaWuX7EiOrnYvLGfQChhBwnAACAWqhs0lhf5g2lpJjlwp25VHl55tC6tDQz4KlJLpU37sOqmPQXniJwAgAA8FBVxR96976UNxQXV/F23s4bSkkxc6jqEgB44z6shkl/URsETgAAAB6obtLYnBzpiivMvKHUVNfhes68obQ07+YN2e1ScrL/78MqmPQXtRXEvyUAAAB4l7viD6dOmcFSs2bkDQUiJv1FXXDFCQAAoIZqUvzh1Clp3Dhp+/bQyxsKdJ4U7wiVK3CeCPW8MAInAACAGqpp8YeWLaWpU0P7S2YgYtLf2iMvjMAJAACgxi6fNNZd8YdQyhuyCk9eP1xCXpiJ3z0AAABqiEljrY3Xz3PkhV1C4AQAAFBDTBprbbx+nvPVpM5WwFA9AEDACPXEY1hDTSeNpT8HplCe9Lc2yAu7hMAJABAQSDyGlbibNJb+HNhCcdLf2iIv7BICJwCA35F4DCuqqvgD/dkaKN5RM868sMxM303qHKiIqwEAfkXiMYIJ/RnBhrywS0LgKQIAAhmJxwgm9GcEI2deWI8e5gTP+/eby7S00LqCylA9AIBfkXgMq6qs+AP9GcGKvDACJwCAn5F4DCuqqvhD7970ZwSvUM8LC6EYEQAQiJiQElbjLP6QmWnmd3TubC4zM6UVK6QrrqA/A8GIwAkA4FckHsNK3BV/OHXKzGVq1oz+DAQbhuoBQDlMWul7TEgJq6hJ8YdTp6Rx46QvvpB27DCH58XESD17Mo+TN3COhr8QOAHAZZi00n9IPIYV1LT4Q1FRxaF6lCCvO87R8CcCJwD4P0xa6X+hnniMwFeTYiYXLkjvv28uk5MvnUt27TKDKs4ltcM5Gv7G73gAICatBFAz7oqZ5OaaV0LOn+dc4k2coxEICJwAQExaCaBm3BUziYw0r0glJXEu8SbO0QgEBE4AoJrlLZw/z6SVAC4VM+nRwywEsX+/uUxLk0aNMoOnYDyXOBzS4cPS7t3m0pdXdy4/RxuGdOaMdPy4uTQMax9XWAc5TgAgJmEF4Jmqipnk5EgffBB85xJ/F2VwnqNzcsy5sPLzzSt9DRqYV/8SEqx5XGEtXHECADEJKwDPOYuZdO1qLu324DyXVDfh76JF5vb6lpRkTiy8ebP07bdSdLQ5V1Z0tPn35s3m31Y6rrAeAicAEJOwAvCOYDuXBFpRBsO49K+yv4H6ZJG3LQDUv+ryFuqjzK1zEkfJXFINCv7kz/yVQGxHXfj6XFKfLi/KILnmFkm+K8qQkyOdPi317y9deaX0/ffmMf3+e/PvG24w/6Y4BOoTOU4AcBlfTcLqzBc4eFC69VZp3jypQwcmcYR/+Dt/JdDa4Q3BMqGzsyjD99+b81CVzy3q2NE3RRmc7ejc2RwWefasOU9WZKTUuLF08aIZoFIcAvWJwAkAyqnvSVgvn8TR+TjNmjGJI/wjUCYVDZR2eFMwTOgcG2sGKFu2mAFT48ZSeLhUUmLmFp08KbVrV/9FGcoX8GnSxHW7VYtuwFos9rsHAFhb+XwB54d8bCyTOML3AiV/JVDagYoSEsyrTadPm1eYIiPNgDAy0vz79GnzSlBCQv22IxiLbsB6CJwAwIeYxBGBJFD6Y6C0AxUdOSI1bGhWtMvPN4Mkh8Nc5ueb66OizP3qU7AV3YA10b0AwIeYaBeBJFD6I5ObBq7CQvPqUr9+UuvWrkUZWrc210dG+ua1CaaiG7AmcpwAwIeYaBeBJFD6o7vJTdu04X3hL87XJjrarFxXvihDQYFvX5tgKboBa6KbAYAPMU4fgSRQ+qNzctPPPpOOHnWd3PToUSY39afL+4hkFmVo2fJScQZ/nLMqm3gY8AW6GgD4UPlx+gUF5vqCAsbpw/cCLW/EZjP/XT65qXMd/CPQ+gjgT3RzAPCxy8fpnz5trjt9mnH68I9AyBtxTm56ww2V59Ewual/BUIfAQIBOU4AUAsOR93G2DvH6R86JO3ZI02fbs6Fwq+28Ad/540E6+SmdT1PBBJv9ZFgOiYIPQROAOCh7Gxzzpm9e80ve1FRZg7AyJGe/fJqt5tfGvbs4csD/M+fk7UG4+Sm3jpPBJK69pFgPCYILQROAOCB7Gxp0SKz6ldiolkmuahIysw0k6cZtgJ4zlmAIDPTnPD28pwmZ5GKtDTrFIfgPFERxwTBgN83AaCGHA7z19L8fPPLXVycFBZmLlNTzfUrV5r7Aai5YCpAwHmiIo4JgoUFTkEArMDhkA4flnbvNpfB+AGYk2MOMUlMrFjly2aTEhLMX1VJYAc8FywFCDhPVMQxQbBgqB6AOguVcevOBPaYmMq3x8RIeXnWS2AHAoW/i1R4A+eJijgmCBYETgDqJJTGrZdPYC/PignsQKDxZ5EKb+A8URHHBMHCQr/hAAg0oTZu3ZnAnpt7aYJOJ2cCe0qKdRLYAXgf54mKOCYIFgROAGot1MatB1MCO4D6wXmiIo4JggVdFECt1WTc+vnzwTVuPVgS2AHUH84TFXFMEAzIcQJQa6E6bj0YEtgB1C/OExVxTGB1BE4Aai3YJq30hNUT2AHUP84TFXFMYGXE+ABqjXHrAAAgVPB1BkCdMG4dAACEAobqAagzxq0DAIBgR+AEwCsYtw4AAIIZvwcDAAAAgBsETgAAAADgBkP1AACAHA7yFAGgOgROAACEuOxs6aOPpL17pfPnzYmru3QxpxugMiYAmAicAAAIYdnZ0qJFUn6+lJgoxcRIRUXmxNa5uUwrAABOXIQHACBEORzmlab8fCk1VYqLk8LCzGVqqrl+5UpzPwAIdQROAACEqJwcc3heYqJks7lus9mkhATzilROjn/aBwCBhMAJAIAQVVho5jTFxFS+PSbG3F5Y6Nt2AUAgInACACBExcaahSCKiirfXlRkbo+N9W27ACAQETgBABCikpLM6nm5uZJhuG4zDOnIEbMwRFKSf9oHAIGEwAkAgBBlt5slx+Pjpaws6exZqbTUXGZlmetHjGA+JwCQKEfuV0w2CADwt5QUs+S4cx6nvDxzeF5amhk0UYocAEwETn7CZIMAgECRkiJ17syPeQBQHb+fEl999VUlJycrKipKffr00fbt26vd/8yZM3rwwQfVunVrRUZGqlOnTlq9erWPWusdzskGMzPNYRCdO5vLzExzfXa2v1sIAAg1druUnCx17WouCZoAwJVfT4vLly/XlClTNGvWLH355Ze69tprNWTIEJ04caLS/YuLizVo0CAdPnxYK1as0L59+/TGG2+oTZs2Pm557THZIAAAAGA9fh2qt3DhQt1zzz2aMGGCJGnx4sX6+OOPtWTJEk2dOrXC/kuWLNHp06e1detWhYeHS5KSk5OrfYwLFy7owoULZX8XFBRIkkpKSlRSUuKlZ1JzOTnSwYPmr3lhYRW3t20rHTggHTpEFaPacr6u/nh9AU/RX2El9FdYCf0VNeFJ/7AZRvkCpL5RXFys6OhorVixQiNGjChbP378eJ05c0Z//vOfK9zmJz/5ia644gpFR0frz3/+s5o3b66xY8fqiSeeUFhlUYik2bNna86cORXWv/vuu4qOjvba8wEAAABgLefOndPYsWN19uxZxcXFVbuv36445efn6+LFi2rZsqXL+pYtW2rv3r2V3ubrr7/Wp59+qp///OdavXq1Dh48qAceeEAlJSWaNWtWpbeZNm2apkyZUvZ3QUGBEhMTNXjwYLcHpz7k5Ejz5knNmlU+oWBBgXT6tDR9OlecaqukpETr16/XoEGDyq5MAoHKCv113z5p1Spp//5LxWw6dZJuvtnM0UTosEJ/BZzor6gJ52i0mrBUVT2Hw6EWLVro97//vcLCwpSenq68vDw999xzVQZOkZGRioyMrLA+PDzcL2+idu2kDh3MQhCpqZLNdmmbYUjffGOWgG3XjsTcuvLXawzURqD21+xs6dVXzfzLxEQpJkYqKpJ27DDPV5MnUwk0FAVqfwUqQ39FdTzpG377ah4fH6+wsDAdP37cZf3x48fVqlWrSm/TunVrderUyWVYXkpKio4dO6bi4uJ6ba+3MNkgAKugmA0AAJf47et5RESE0tPTtWHDhrJ1DodDGzZsUN++fSu9zfXXX6+DBw/Kcdmn9P79+9W6dWtFRETUe5u9xTnZYI8e0qlT5vCXU6fMK038egsgUOTkmHPNJSa6Xh2XzL8TEswrUjk5/mkfAAC+5NehelOmTNH48ePVs2dP9e7dWy+++KKKiorKquyNGzdObdq00fz58yVJ999/v1555RU9/PDDeuihh3TgwAE9/fTTmjx5sj+fRq0w2SCAQFdYaOY0xcRUvj0mRsrLM/cDQpHDwed4qKMPhBa/Bk6jR4/WyZMnNXPmTB07dkzdu3fXmjVrygpG5OTkyH5Z70tMTNTatWv1q1/9St26dVObNm308MMP64knnvDXU6gT52SDABCIYmPNQhBFRebwvPKKisztlRW6AYJddrY5lHXv3ktFU7p0MYfjM3IkNNAHQo/fi0NkZGQoIyOj0m2bNm2qsK5v3776/PPP67lVAICkJPNLQFXFbI4cMYcYUwEUoSY7W1q0qGLRlMxMKTeXYfehgD4QmriYCACoFMVsgIoomgL6QOji4w4AUCWK2QCuKJoSPBwO6fBhafduc1nTQMeTPlDbx0Bg8vtQPQBAYKOYDXAJRVOCQ13yk2raB3btkt59lxyoYELgBABwi2I2gImiKdZX1/ykmvSBCxek9983l+RABQ9+LwQAAKghZ9GU3FyzSMrlnEVTUlIomhKovJGf5K4P5OaaV5jOnycHKtgQOAEAANQQRVOszRs5au76QGSkeUUqKYk8uGDD2xoAAMADFE2xrprkJ50/7z5Hrbo+MGqUGTzV9TEQeMhxAgAA8BBFU6zJmzlqVfWBnBzpgw/IgwtGBE4AAAC1QNEU6/H2xN6V9QEmDw9e/C4CAACAkOCLHDXy4IIXV5wAAAD8xOFguJ+vOfOTnPM45eWZQ+fS0syAxhs5ar54DPgegRMAAIAf1GUSVtSNL3LUyIMLPgROAAAAPlbXSVhRd77IUSMPLrgQ8wIAAPiQNyZhBeB7BE4AAAA+5I1JWAH4HkP1AHgFCc4AUDM1mYQ1L48JUoFAQ+AEoM5IcAaAmvPmJKwAfIffgwHUiTPBOTPTnJuic2dzmZlprs/O9ncLASCwOCdIzc01J0S9nHOC1JQUJkgFAo1HgdOuXbv029/+Vq+99pry8/NdthUUFGjixIlebRyAwEaCMwB4jglSAWuq8Vty3bp16t27t5YtW6ZnnnlGXbp00caNG8u2f//991q6dGm9NBJAYCLBGQBqxzlBao8e0qlT0v795jItjVLkQKCqcY7T7Nmz9dhjj2nevHkyDEPPPfecbrnlFr3//vsaOnRofbYRQIAiwRkAao8JUhGKrFxMqsaB03/+8x+98847kiSbzabHH39cCQkJuv3227Vs2TL16tWr3hoJIDCR4AwAdcMEqQglVi8mVePAKTIyUmfOnHFZN3bsWNntdo0ePVovvPCCt9sGIMA5E5wzM82cpsuH6zkTnNPSSHAGACDUOYtJ5eebQ/xjYswfWDMzzUIpVhiiWuPAqXv37tq4caPS09Nd1t9xxx0yDEPjx4/3euMABDZngnNurpnQnJBw6UR45AgJzgAAoGIxKecPrc5iUllZZjGpzp0D+ztDjZt2//33Ky8vr9JtY8aM0dtvv60bb7zRaw0DYA0kOAMAgOoESzGpGl9xGjlypEaOHFnl9rFjx2rs2LFeaRQAayHBGQAAVCVYiknVOHACgOqQ4AwAACoTLMWk+D0YAAAAQL1xFpPKzTWLR13OWUwqJSXwi0kROAEAAACoN85iUvHxZiGIs2el0lJzmZVlnWJSDNUDYClWnjgPAIBQ5Swm5ZzHKS/PHJ6XlmYGTVYoJlXrwKm4uFiHDh1S+/bt1aAB8ReA+mf1ifMAAAhlVi8m5XEzz507p7vvvlvR0dG6+uqrlfN/dQMfeughLViwwOsNBADp0sR5mZnmJf3Onc1lZqa5Pjvb3y0EAADuOItJde1qLq0SNEm1CJymTZumXbt2adOmTYqKiipbP3DgQC1fvtyrjQMAqeLEeXFxUljYpYnz8vPNifMcDn+3FAAABCuPx9itXLlSy5cv13XXXSfbZTNYXX311frqq6+82jgAkDybOI+S6AAAoD54HDidPHlSLVq0qLC+qKjIJZACAG8Jlonzgh2FOwAAwczjwKlnz576+OOP9dBDD0lSWbD05ptvqm/fvt5tHQAoeCbOC2YU7gAABDuPA6enn35aw4YNU1ZWlkpLS/XSSy8pKytLW7du1d///vf6aCOAEOecOC8z08xpuvzitnPivLS0wJ84L1g5C3fk55vDKWNizGA2M9Oc7HDyZIInAID1eTyI4oYbbtCuXbtUWlqqrl27at26dWrRooW2bdum9PT0+mgjgBAXLBPnBSMKdwAAQoVHV5xKSkp03333acaMGXrjjTfqq00AUEEwTJwXjCjcUT3yvgAgeHgUOIWHh+uDDz7QjBkz6qs9AFAlq0+cF4wo3FE18r4AILh4/HVjxIgRWrlyZT00BQDcs/LEecHo8sIdlQnVwh1M2AwAwcfj4hAdO3bUU089pS1btig9PV0x5X5mnDx5stcaBwAIbBTuqKh83pfzmDjzvrKyzLyvzp0J/AHASjwOnN566y01adJEO3bs0I4dO1y22Ww2AicACCHOwh25uWZAkJBwqarekSOhWbiDvC8ACE4eB06HDh2qj3YAACyKwh2uyPuCE8VBgODiceB0OcMwJF2aBBcAEJoo3HEJEzZDojgIEIxq9ZH2//7f/1PXrl3VsGFDNWzYUN26ddM777zj7bYBACyEwh0mZ95Xbq6Z53U5Z95XSkpo5X2FGoqDAMHJ4ytOCxcu1IwZM5SRkaHrr79ekrR582b98pe/VH5+vn71q195vZEAAFgFeV+hjeIgQPDyOHB6+eWX9frrr2vcuHFl62655RZdffXVmj17NoETAKBSoZTvQd5X6KI4CC4XSue9UOBx4PTtt9+qX79+Fdb369dP3377rVcaBQAILqGY70HeV2iiOAicQvG8F+w8Pn136NBB7733XoX1y5cvV8eOHb3SKABA8AjlfA/yvkIPk0JDCu3zXjDz+IrTnDlzNHr0aP3jH/8oy3HasmWLNmzYUGlABQAIXeR7INQwKTQ47wUvj1+u2267TV988YXi4+O1cuVKrVy5UvHx8dq+fbtGjhxZH20EAFiUJ/keQDBwFgeJjze/IJ89K5WWmsusLIqDhALOe8GrVvM4paen649//KO32wIACDKBmu9BwjbqE8VBQlugnvdQdx4HTqtXr1ZYWJiGDBnisn7t2rVyOBwaNmyY1xoHALC2QJwMloRt+ALFQUJXIJ734B0ev32nTp2qixcvVlhvGIamTp3qlUYBAIJDoE0GS8I2fIniIKEp0M578B6P38IHDhxQampqhfVdunTRwYMHvdIoAEBwCKR8j/IJ23FxUljYpYTt/HwzYdvhqP+2AAhegXTeg3d5/JI1btxYX3/9dYX1Bw8eVExVgzkBACHLme/Ro4d06pS0f7+5TEsz1/tqeBwJ2wB8JVDOe/Auj3Ocbr31Vj3yyCP66KOP1L59e0lm0PToo4/qlltu8XoDAQDWFwj5HiRsA/ClQDjvwbs8DpyeffZZDR06VF26dFFCQoIk6ciRI+rfv7+ef/55rzcQABAcnPke/kLCNgBf8/d5D97lceDUuHFjbd26VevXr9euXbvUsGFDdevWTTfeeGN9tA8AAK9gYlIAQF3Uah4nm82mwYMHa/DgwZKkM2fOeLNNAAB4nTNhOzfXTNBOSDCH5xUVmUETCdsAgOp4/PHwzDPPaPny5WV/jxo1Ss2aNVObNm20a9curzYOgHsOh3T4sLR7t7mkIhhQNRK2AQC15fEVp8WLF+tPf/qTJGn9+vVav369/va3v+m9997Tr3/9a61bt87rjQRQOSbyBDxHwjYAoDY8DpyOHTumxMRESdKqVas0atQoDR48WMnJyerTp4/XGwigcs6JPPPzzfLKziFHmZnmUCR+PQeqRsI2AMBTHv++1rRpU+Xm5kqS1qxZo4EDB0qSDMPQxYsXvds6AJViIk8AAADf8viK009/+lONHTtWHTt21KlTpzRs2DBJUmZmpjp06OD1BgKoyJOJPPlVHQAAoO48Dpx+97vfKTk5Wbm5uXr22WfVqFEjSdK3336rBx54wOsNBFARE3kCAAD4lseBU3h4uB577LEK63/1q195pUEA3GMiTwAAAN+ihhBgQc6JPHNzzYk7L+ecyDMlhYk8AQAAvIXACbAg50Se8fHmRJ5nz0qlpeYyK4uJPAEAALzN46F6QChwOAJ/jhfnRJ7OeZzy8szheWlpZtBEKXKEKiu8fwEA1kPgBJRjpUllmcgTcGWl9y8AwFpqHTgVFxfrxIkTcpSbKCaJpApYmBUnlWUiT8BkxfcvAMA6PA6cDhw4oIkTJ2rr1q0u6w3DkM1mYxJcWFb5SWWd8yM5J5XNyjInle3cmSs6QKDh/QsAqG8eB0533XWXGjRooFWrVql169aylZ99E7AoJpUFrIv3LwCgvnkcOO3cuVM7duxQly5d6qM9gN8wqSxgXVZ9/wZbIYtgez4AcDmPA6fU1FTl5+fXR1sAv2JSWcC6rPj+DbZCFsH2fACgPI9/B3rmmWf0+OOPa9OmTTp16pQKCgpc/gFWxaSygHVZ7f3rLGSRmWnOu9a5s7nMzDTXZ2f7u4WeCbbnAwCV8fiK08CBAyVJP/7xj13WUxwCVuecVDY310wkT0i4VJXryBEmlQUCmZXev8FWyCLYng8AVMXjwGnjxo310Q4gIDCpLGBdVnn/Blshi2B7PgBQFY8DpwEDBtRHO4CAwaSyqAmS4AOTFd6/Vi1kUZVgez4AUBWPA6d//OMf1W6/8cYbPW7Eq6++queee07Hjh3Ttddeq5dfflm9e/d2e7tly5ZpzJgxuvXWW7Vy5UqPHxeoCpPKojokwQe2QH//WrGQRXWC7fkAQFU8Dpx+8IMfVFh3+VxOnuY4LV++XFOmTNHixYvVp08fvfjiixoyZIj27dunFi1aVHm7w4cP67HHHlP//v09ejwAqAtnEnx+vjk0yZlHk5lp5tdMnkzwhOo5C1lkZrrmBEmXClmkpQVOIQt3gu35AEBVPB688N///tfl34kTJ7RmzRr16tVL69at87gBCxcu1D333KMJEyYoNTVVixcvVnR0tJYsWVLlbS5evKif//znmjNnjq666iqPHxMAaqN8EnxcnBQWdikJPj/fTIJ3OPzdUgQyZyGL+HizcMLZs1JpqbnMygqsQhY1EWzPBwCq4vEVp8aNG1dYN2jQIEVERGjKlCnasWNHje+ruLhYO3bs0LRp08rW2e12DRw4UNu2bavydk899ZRatGihu+++W5999lm1j3HhwgVduHCh7G9nyfSSkhKVlJTUuK0IDA6H+evld99JjRqZScflP4ydryuvL7wtJ0c6eNAcBhYWVnF727bSgQPSoUM1/3Wd/hqaOnSQHnxQWrVK2r9fOn7cHM7Ws6d0003m9kDsElX1V6s+HwQ3zq+oCU/6h8eBU1Vatmypffv2eXSb/Px8Xbx4US1btqxwX3v37q30Nps3b9Zbb72lnTt31ugx5s+frzlz5lRYv27dOkVHR3vUXgSePXuq3rZ+/XrfNQQh49Zb3e+zZ0/1fbMy9NfQlJJScWjnV1+Z/wJZVf3Vqs8HwY3zK6pz7ty5Gu/rceD073//2+VvwzD07bffasGCBerevbund+eRwsJC3XnnnXrjjTcUHx9fo9tMmzZNU6ZMKfu7oKBAiYmJGjx4sOIqy2JFQNq3T1q8WDp9WmrTRoqOls6dMys1XXGF9MtfmpW0JPOXg/Xr12vQoEEKDw/3b8MRVHJypHnzpGbNKk90Lygw++j06Z5dcaK/wiror7AS+itqwjkarSY8Dpy6d+8um80mo9zU7Nddd121eUmViY+PV1hYmI4fP+6y/vjx42rVqlWF/b/66isdPnxYw4cPL1vn+L9kggYNGmjfvn1q3769y20iIyMVGRlZ4b7Cw8N5E1mEwyH95S/m0I/LE49jYqSOHc0x9H/9q7nt8mF7vMbwtnbtzCFHVSXBf/ONmQTfrp3n+Rz0V1gJ/RVWQn9FdTzpGx4HTocOHXL52263q3nz5oqKivL0rhQREaH09HRt2LBBI0aMkGQGQhs2bFBGRkaF/bt06aLdu3e7rHvyySdVWFiol156SYmJiR63AYGPyRURKJxJ8Lm5ZsCekHCpqt6RIyTBAwAQzDwKnEpKSjRx4kQtXrxYHTt29EoDpkyZovHjx6tnz57q3bu3XnzxRRUVFWnChAmSpHHjxqlNmzaaP3++oqKidM0117jcvkmTJpJUYT2CB5MrwtvqMnltSopZctw5j1NenpkEn5ZmBk2UIgcAa2Aic3jKo8ApPDy8Qo5TXY0ePVonT57UzJkzdezYMXXv3l1r1qwpKxiRk5MjO704pDG5IrzJG5PXpqSYOXV84AKANTGROWrD46F6v/jFL/TWW29pwYIFXmtERkZGpUPzJGnTpk3V3vbtt9/2WjsQmJhcEd7izclr7XaGhgKAFTGROWrL48CptLRUS5Ys0SeffKL09HTFlBs/tXDhQq81DpDIK4F3lJ+81hmAOyevzcoyJ6/t3Jm+BADBis8C1IXHgdOePXuUlpYmSdq/f7/LNlv5zH3AS8grQV1RZAQAwGcB6sLjwGnjxo310Q7ALfJKUBcUGQEA8FmAuvA4cAL8ibwS1BZFRgAAfBagLvitHkBIcBYZyc01i4pczllkJCWFIiMAEMz4LEBdEDgBCAnOIiPx8Wby79mzUmmpuczKosgIAIQCPgtQF3QLACHDWWSkRw/p1Clp/35zmZZG+VkACBV8FqC2yHECEFIoMgIA4LMAtUHgBCDkUGQEAMBnATxFXA0AAAAAbhA4AQAAAIAbDNUDAACwMIeDXB3AFwicAAAALCo7W/roI2nvXun8eXPy1i5dzJLbVIcDvIvACQAAwIKys6VFi6T8fCkxUYqJkYqKpMxMc4JXSmsD3sWFXAAAAItxOMwrTfn5UmqqFBcnhYWZy9RUc/3KleZ+ALyDwAkAAMBicnLM4XmJiZLN5rrNZpMSEswrUjk5/mkfEIwInAAAACymsNDMaYqJqXx7TIy5vbDQt+0CghmBEwAAgMXExpqFIIqKKt9eVGRuj431bbuAYEbgBAAAYDFJSWb1vNxcyTBctxmGdOSIWRgiKck/7QOCEYETAACAxdjtZsnx+HgpK0s6e1YqLTWXWVnm+hEjmM8J8CbeTgAAABaUkmKWHO/RQzp1Stq/31ympVGKHKgPzOMEAABgUSkpUufOZvW8wkIzpykpiStNQH0gcAIAALAwu11KTvZ3K4Dgx+8RAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsETgAAAADgBoETAAAAALhB4AQAAAAAbhA4AQAAAIAbBE4AAAAA4AaBEwAAAAC4QeAEAAAAAG408HcDAAQHh0PKyZEKC6XYWCkpSbLz0wwAANXi89M6CJwA1Fl2tvTRR9LevdL581JUlNSlizRypJSS4u/WAQAQmPj8tBYCJwB1kp0tLVok5edLiYlSTIxUVCRlZkq5udLkyZz8AQAoj89P6+FCIIBaczjMX8ry86XUVCkuTgoLM5epqeb6lSvN/QAAgInPT2sicAJQazk55vCCxETJZnPdZrNJCQnmL2o5Of5pHwDvceZhSOaSL3RA7fH5aU0M1QNQa4WF5pjsmJjKt8fESHl55n4ArMuZh3HwoHTrrdK8eVKHDuRhALXF56c1ccUJQK3FxpqJrEVFlW8vKjK3x8b6tl0AvMeZh5GZKTVrZq5r1sz8e9EiczsAz/D5aU0ETgBqLSnJrP6TmysZhus2w5COHDF/jU5K8k/7ANRN+TwM55e42FjyMIC64PPTmgicANSa3W4O1YmPl7KypLNnpdJSc5mVZa4fMYL5KACrIg8DqB98floTOU5g4jW4VV0fSUkxS6Y656HIyzOHF6SlmSd98h8A6yIPA6g/fH5aD4FTiGPiNbhTkz6SkiJ17kwADgSby/Mw4uIqbicPA6gbPj+thcAphDHxGtzxpI/Y7VJysl+bC8DLnHkYmZlmTtPlnHkYaWnkYQB1weendRDPhigmXoM79BEA5fMwCgrM9QUF5GEACD2c6kIUCb9whz4CQLqUh9Gjh3T6tLnu9GnzShMjEwCEEobqhSgSfuEOfQSAkzMP49Ahac8eafp0qV07rjQBCC2c8kIUE6/BHfoIgMvZ7ZdymUheBxCKOO2FKCZegzv0EQAAgEsInEIUE6/BHfoIAADAJXzlCWGXJ/yeOiXt328uSfiFE30EAADARHGIEMfEa3CHPgIAAEDgBDHxGtyjjwAAgFDHb8YAAAAA4AaBEwAAAAC4QeAEAAAAAG4QOAEAAACAGwROAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsETgAAAADgBoETAAAAALhB4AQAAAAAbhA4AQAAAIAbBE4AAAAA4AaBEwAAAAC4QeAEAAAAAG4QOAEAAACAGwROAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsN/N0AwMnhkHJypMJCKTZWSkqS7IT2QNDgPQ4AsDICJwSE7Gzpo4+kvXul8+elqCipSxdp5EgpJcXfrQNQV7zHAQBWR+AEv8vOlhYtkvLzpcREKSZGKiqSMjOl3Fxp8mS+WAFWxnscABAMGCQBv3I4zF+h8/Ol1FQpLk4KCzOXqanm+pUrzf0AWA/vcQBAsCBwgl/l5JhDdxITJZvNdZvNJiUkmL9W5+T4p30A6ob3OAAgWBA4wa8KC818h5iYyrfHxJjbCwt92y4A3sF7HAAQLAIicHr11VeVnJysqKgo9enTR9u3b69y3zfeeEP9+/dX06ZN1bRpUw0cOLDa/RHYYmPNJPGiosq3FxWZ22NjfdsuAN7BexwAECz8HjgtX75cU6ZM0axZs/Tll1/q2muv1ZAhQ3TixIlK99+0aZPGjBmjjRs3atu2bUpMTNTgwYOVl5fn45bDG5KSzMpaubmSYbhuMwzpyBEzaTwpyT/tA1A3vMcBAMHC74HTwoULdc8992jChAlKTU3V4sWLFR0drSVLllS6/5/+9Cc98MAD6t69u7p06aI333xTDodDGzZs8HHL4Q12u1mOOD5eysqSzp6VSkvNZVaWuX7ECOZ6AayK9zgAIFj4tRx5cXGxduzYoWnTppWts9vtGjhwoLZt21aj+zh37pxKSkp0xRVXVLr9woULunDhQtnfBQUFkqSSkhKVlJTUofXwlg4dpAcflFatkvbvl44fN4fu9Owp3XSTud2Tl8r5uvL6wgpCob96+z0O/wmF/orgQX9FTXjSP2yGUX7whO8cPXpUbdq00datW9W3b9+y9Y8//rj+/ve/64svvnB7Hw888IDWrl2r//znP4qKiqqwffbs2ZozZ06F9e+++66io6Pr9gQAAAAAWNa5c+c0duxYnT17VnFxcdXua+kJcBcsWKBly5Zp06ZNlQZNkjRt2jRNmTKl7O+CgoKyvCh3B8ef9u279Ovs+fPmr7OdOkk33yx17uzv1gW2kpISrV+/XoMGDVJ4eLi/mwNUi/4KK6G/wkror6gJ52i0mvBr4BQfH6+wsDAdP37cZf3x48fVqlWram/7/PPPa8GCBfrkk0/UrVu3KveLjIxUZGRkhfXh4eEB+ybKzpZefdWcGDIx0SzXW1Qk7dghffONNHmymUyN6gXyawyUR3+FldBfYSX0V1THk77h13TciIgIpaenuxR2cBZ6uHzoXnnPPvus5s6dqzVr1qhnz56+aKrPOBzSRx+ZQVNqqhQXJ4WFmcvUVHP9ypXmfgAAAAB8w+91jKZMmaI33nhDS5cuVXZ2tu6//34VFRVpwoQJkqRx48a5FI945plnNGPGDC1ZskTJyck6duyYjh07pu+++85fT8GrcnKkvXvNK002m+s2m01KSDCvSOXk+Kd9AAAAQCjye47T6NGjdfLkSc2cOVPHjh1T9+7dtWbNGrVs2VKSlJOTI/tldWpff/11FRcX6/bbb3e5n1mzZmn27Nm+bHq9KCw0c5piYirfHhMj5eWZ+wEAAADwDb8HTpKUkZGhjIyMSrdt2rTJ5e/Dhw/Xf4P8KDbWLARRVGQOzyuvqMjcHhvr+7YBAAAAocrvQ/XgKilJ6tJFys2VyheKNwzpyBGzMERSkn/aBwAAAIQiAqcAY7dLI0dK8fFSVpZ09qxUWmous7LM9SNGmPsBAAAA8A2+fgeglBSz5HiPHtKpU+ZcTqdOSWlplCIHAAAA/CEgcpxQUUqKOdFtTo5ZCCI21hyex5UmAAAAwPcInAKY3S4lJ/u7FQAAAAC4fgEAAAAAbhA4AQAAAIAbBE4AAAAA4AaBEwAAAAC4QeAEAAAAAG4QOAEAAACAGwROAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsETgAAAADgRgN/NwAAAAQHh0PKyZEKC6XYWCkpSbLzEy2AIEHgBAAA6iw7W/roI2nvXun8eSkqSurSRRo5UkpJ8XfrAKDuCJwAAECdZGdLixZJ+flSYqIUEyMVFUmZmVJurjR5MsETAOvjAjoAAKg1h8O80pSfL6WmSnFxUliYuUxNNdevXGnuBwBWRuCEoOIcXy+ZSz6oAaB+5eSYw/MSEyWbzXWbzSYlJJhXpJznZsAdh0M6fFjavdtc8lmOQMFQPQQN5/j6gwelW2+V5s2TOnRgfD0A1KfCQjOnKSam8u0xMVJenrkf4A65cghkBE4ICpePr09ONtc1a8b4egCob7Gx5pfboiJzeF55RUXm9thY37cN1kKuHAIdQ/VgeeXH1zs/nGNjGV8PAPUtKcm8IpCbKxmG6zbDkI4cMb/sJiX5p32wBnLlYAUETrA8xtcDgP/Y7eYwqvh4KStLOntWKi01l1lZ5voRI5jPCdXjsxxWwGkMlleT8fXnzzO+HgDqS0qKOYyqRw/p1Clp/35zmZbG8CrUTLB+llPoIriQ4wTLY3w9APhfSorUubN5RaCw0DznJiVxpQk1E4yf5RS6CD6czmB5jK8HgMBgt5sFerp2NZcETaipYPssdxa6yMw0h6t27mwuMzPN9dnZ/m4haoNTGiyv/Pj6ggJzfUEB4+sBALCCYMqVo9BF8LJA9wPcu3x8/enT5rrTpxlfDwCAVQRLrhyFLoIXOU4IGs7x9YcOSXv2SNOnS+3aWePXKQDe43CQZwNYVTDkyjEpdPAicEJQsdvNE+yePdY70QKoO5KxAetz5spZVTAWuoCJr5UAgKBAMjaAQBBshS5wCYETAMDySMYGECiCqdAFXPGSAQAsj2RsAIEkWApdwBU5TgAAyyMZG0CgCYZCF3BF4AQAsDySsQEEIqsXuoArYl4AgOWRjA0AqG8ETgAAyyMZGwBQ3/gIAQA/cU7UKplLKr7VDcnYAEKVwyEdPizt3m0u+TypH+Q4AYAfOCdqPXhQuvVWad48qUMHJmqtK5KxAYQaJv72HQInAPAx50St+fmXkoabNTMnas3N5epIXZGMDSBUXP55kphoVhAtKuLzpL7wGxwA+FD5iVqdVd5iY5moFQBQc0z87XsETgDgQ0zUCgDwBj5PfI/ACQB8qCYTtZ4/z0StAIDq8XniewROAOBDl0/UWhkmagUA1ASfJ75H4AQAPsRErQAAb+DzxPcInADAh8pP1FpQYK4vKGCiVgBAzTHxt+9xKAHAxy6fqPX0aXPd6dNM1AoA8AwTf/sW8zgBgB84J2o9dEjas0eaPl1q145fBgEAnmHib98hcAIAP7HbzQ+3PXv4kAMA1B4Tf/sGH9MAAAAA4AaBEwAAAAC4QeAEAAAAAG4QOAEAAACAGwROAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsETgAAAADgBoETAAAAALhB4AQAAAAAbjTwdwMAAAC8yeGQcnKkwkIpNlZKSpLs/FQMoI4InAAAQNDIzpY++kjau1c6f16KipK6dJFGjpRSUvzdOgBWRuAEAACCQna2tGiRlJ8vJSZKMTFSUZGUmSnl5kqTJxM8Aag9LlwDAADLczjMK035+VJqqhQXJ4WFmcvUVHP9ypXmfgBQGwROAADA8nJyzOF5iYmSzea6zWaTEhLMK1I5Of5pH1AVh0M6fFjavdtcEtwHLobqAQAAyyssNHOaYmIq3x4TI+XlmfsBgYKcPGshcAIAAJYXG2t+6SwqMofnlVdUZG6PjfV924DKkJNnPQzVAwAAlpeUZP5Sn5srGYbrNsOQjhwxv4QmJfmnfcDlyMmzJgInAABgeXa7ObwpPl7KypLOnpVKS81lVpa5fsQI5nNCYCAnz5oYqgcAAHyiviemTUkxhzc5c0by8szheWlpZtDEsCcECnLyrInACQAA1DtfJcGnpEidO9dvgAbUFTl51kTgBAAA6pWvk+Dtdik52Xv3B3ibMycvM9PMabp8uJ4zJy8tjZy8QMPvLwAAoN6QBA9URE6eNfFyAACAekMSPFA5Z05ejx7SqVPS/v3mMi2NUuSBiqF6AACg3pAED39wFiKRzGW7doF59YacPGshcAIAAPWGJHj4mrMQycGD0q23SvPmSR06eL8QibeQk2cdxLMAAKDeMDEtfMlZiCQzU2rWzFzXrJn596JF5nagtgicAABAvSEJHr5SvhCJ8ypmbCyFSOAdnKYAAEC9IgkevkAhEtS3gAicXn31VSUnJysqKkp9+vTR9u3bq93//fffV5cuXRQVFaWuXbtq9erVPmopAACojZQUaepU6amnpBkzzOUTTxA0wXtqUojk/HkKkaD2/B44LV++XFOmTNGsWbP05Zdf6tprr9WQIUN04sSJSvffunWrxowZo7vvvluZmZkaMWKERowYoT179vi45QAAwBPOJPiuXc0lw/PgTZcXIqkMhUhQV34/ZS1cuFD33HOPJkyYoNTUVC1evFjR0dFasmRJpfu/9NJLGjp0qH79618rJSVFc+fOVVpaml555RUftxwAAACBgkIkqG9+LUdeXFysHTt2aNq0aWXr7Ha7Bg4cqG3btlV6m23btmnKlCku64YMGaKVK1dWuv+FCxd04cKFsr8LCgokSSUlJSopKanjM0Agcr6uvL6wAvorrIT+ikB3yy3S0aPSgQNSYqLZT4uKSpSbK7VsKQ0fLl28aP4DJM/OZ34NnPLz83Xx4kW1bNnSZX3Lli21d+/eSm9z7NixSvc/duxYpfvPnz9fc+bMqbB+3bp1io6OrmXLYQXr16/3dxOAGqO/wkrorwhkgwa5/t2v36X++tVX5j/A6dy5czXeN+gnwJ02bZrLFaqCggIlJiZq8ODBiqtsJj5YXklJidavX69BgwYpPDzc380BqkV/hZXQX2EVDof0zTclys5er5SUQWrbNpycOlTKORqtJvwaOMXHxyssLEzHjx93WX/8+HG1atWq0tu0atXKo/0jIyMVGRlZYX14eDgn/SDHawwrob/CSuivsIJ27czy4+3a0V9RNU/6hl9j74iICKWnp2vDhg1l6xwOhzZs2KC+fftWepu+ffu67C+ZQwaq2h8AAAAA6srvQ/WmTJmi8ePHq2fPnurdu7defPFFFRUVacKECZKkcePGqU2bNpo/f74k6eGHH9aAAQP0wgsv6KabbtKyZcv0r3/9S7///e/9+TQAAAAABDG/B06jR4/WyZMnNXPmTB07dkzdu3fXmjVrygpA5OTkyH7ZoNR+/frp3Xff1ZNPPqnf/OY36tixo1auXKlrrrnGX08BAAAAQJDze+AkSRkZGcrIyKh026ZNmyqs+9nPfqaf/exn9dwqAAAAADBRXwQAAAAA3CBwAgAAAAA3CJwAAAAAwA0CJwAAAABwg8AJAAAAANwgcAIAAAAANwicAAAAAMANAicAAAAAcIPACQAAAADcaODvBviaYRiSpIKCAj+3BPWlpKRE586dU0FBgcLDw/3dHKBa9FdYCf0VVkJ/RU04YwJnjFCdkAucCgsLJUmJiYl+bgkAAACAQFBYWKjGjRtXu4/NqEl4FUQcDoeOHj2q2NhY2Ww2fzcH9aCgoECJiYnKzc1VXFycv5sDVIv+Ciuhv8JK6K+oCcMwVFhYqCuvvFJ2e/VZTCF3xclutyshIcHfzYAPxMXFcaKEZdBfYSX0V1gJ/RXuuLvS5ERxCAAAAABwg8AJAAAAANwgcELQiYyM1KxZsxQZGenvpgBu0V9hJfRXWAn9Fd4WcsUhAAAAAMBTXHECAAAAADcInAAAAADADQInAAAAAHCDwAkAAAAA3CBwgiW9+uqrSk5OVlRUlPr06aPt27dXue8bb7yh/v37q2nTpmratKkGDhxY7f6At3nSXy+3bNky2Ww2jRgxon4bCFzG0/565swZPfjgg2rdurUiIyPVqVMnrV692ketRajztL+++OKL6ty5sxo2bKjExET96le/0vnz533UWlgdgRMsZ/ny5ZoyZYpmzZqlL7/8Utdee62GDBmiEydOVLr/pk2bNGbMGG3cuFHbtm1TYmKiBg8erLy8PB+3HKHI0/7qdPjwYT322GPq37+/j1oKeN5fi4uLNWjQIB0+fFgrVqzQvn379MYbb6hNmzY+bjlCkaf99d1339XUqVM1a9YsZWdn66233tLy5cv1m9/8xscth1VRjhyW06dPH/Xq1UuvvPKKJMnhcCgxMVEPPfSQpk6d6vb2Fy9eVNOmTfXKK69o3Lhx9d1chLja9NeLFy/qxhtv1MSJE/XZZ5/pzJkzWrlypQ9bjVDlaX9dvHixnnvuOe3du1fh4eG+bi5CnKf9NSMjQ9nZ2dqwYUPZukcffVRffPGFNm/e7LN2w7q44gRLKS4u1o4dOzRw4MCydXa7XQMHDtS2bdtqdB/nzp1TSUmJrrjiivpqJiCp9v31qaeeUosWLXT33Xf7opmApNr117/85S/q27evHnzwQbVs2VLXXHONnn76aV28eNFXzUaIqk1/7devn3bs2FE2nO/rr7/W6tWr9ZOf/MQnbYb1NfB3AwBP5Ofn6+LFi2rZsqXL+pYtW2rv3r01uo8nnnhCV155pcvJFqgPtemvmzdv1ltvvaWdO3f6oIXAJbXpr19//bU+/fRT/fznP9fq1at18OBBPfDAAyopKdGsWbN80WyEqNr017Fjxyo/P1833HCDDMNQaWmpfvnLXzJUDzXGFSeElAULFmjZsmX66KOPFBUV5e/mAC4KCwt155136o033lB8fLy/mwO45XA41KJFC/3+979Xenq6Ro8erenTp2vx4sX+bhpQwaZNm/T000/rtdde05dffqkPP/xQH3/8sebOnevvpsEiuOIES4mPj1dYWJiOHz/usv748eNq1apVtbd9/vnntWDBAn3yySfq1q1bfTYTkOR5f/3qq690+PBhDR8+vGydw+GQJDVo0ED79u1T+/bt67fRCFm1Ob+2bt1a4eHhCgsLK1uXkpKiY8eOqbi4WBEREfXaZoSu2vTXGTNm6M4779SkSZMkSV27dlVRUZHuvfdeTZ8+XXY71xNQPXoILCUiIkLp6ekuiZ0Oh0MbNmxQ3759q7zds88+q7lz52rNmjXq2bOnL5oKeNxfu3Tpot27d2vnzp1l/2655Rb98Ic/1M6dO5WYmOjL5iPE1Ob8ev311+vgwYNlAb4k7d+/X61btyZoQr2qTX89d+5cheDIGfRTKw01YgAWs2zZMiMyMtJ4++23jaysLOPee+81mjRpYhw7dswwDMO48847jalTp5btv2DBAiMiIsJYsWKF8e2335b9Kyws9NdTQAjxtL+WN378eOPWW2/1UWsR6jztrzk5OUZsbKyRkZFh7Nu3z1i1apXRokUL47e//a2/ngJCiKf9ddasWUZsbKzxv//7v8bXX39trFu3zmjfvr0xatQofz0FWAxD9WA5o0eP1smTJzVz5kwdO3ZM3bt315o1a8oSRHNyclx+UXr99ddVXFys22+/3eV+Zs2apdmzZ/uy6QhBnvZXwJ887a+JiYlau3atfvWrX6lbt25q06aNHn74YT3xxBP+egoIIZ721yeffFI2m01PPvmk8vLy1Lx5cw0fPlzz5s3z11OAxTCPEwAAAAC4wc+cAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsETgAAAADgBoETAAAAALhB4AQAAAAAbhA4AQAAAIAbBE4AAAAA4AaBEwAAfvDtt99q7Nix6tSpk+x2ux555BF/NwkAUA0CJwCAzxUXF/u7CV5T2+dy4cIFNW/eXE8++aSuvfZaL7cKAOBtBE4AgHr3gx/8QBkZGXrkkUcUHx+vIUOG6PDhw7LZbNq5c2fZfmfOnJHNZtOmTZskSZs2bZLNZtOGDRvUs2dPRUdHq1+/ftq3b1+Vj1VcXKyMjAy1bt1aUVFRatu2rebPn+/yGPfdd59atmypqKgoXXPNNVq1alXZ9g8++EBXX321IiMjlZycrBdeeMHl/pOTkzV37lyNGzdOcXFxuvfeeyVJmzdvVv/+/dWwYUMlJiZq8uTJKioqqrKdycnJeumllzRu3Dg1btzYk8MJAPADAicAgE8sXbpUERER2rJlixYvXuzRbadPn64XXnhB//rXv9SgQQNNnDixyn0XLVqkv/zlL3rvvfe0b98+/elPf1JycrIkyeFwaNiwYdqyZYv++Mc/KisrSwsWLFBYWJgkaceOHRo1apTuuOMO7d69W7Nnz9aMGTP09ttvuzzG888/r2uvvVaZmZmaMWOGvvrqKw0dOlS33Xab/v3vf2v58uXavHmzMjIyPHqeAIDA1cDfDQAAhIaOHTvq2WefLfv78OHDNb7tvHnzNGDAAEnS1KlTddNNN+n8+fOKioqqsG9OTo46duyoG264QTabTW3bti3b9sknn2j79u3Kzs5Wp06dJElXXXVV2faFCxfqxz/+sWbMmCFJ6tSpk7KysvTcc8/prrvuKtvvRz/6kR599NGyvydNmqSf//znZXlKHTt21KJFizRgwAC9/vrrlbYTAGAtXHECAPhEenp6rW/brVu3sv+3bt1aknTixIlK973rrru0c+dOde7cWZMnT9a6devKtu3cuVMJCQllQVN52dnZuv76613WXX/99Tpw4IAuXrxYtq5nz54u++zatUtvv/22GjVqVPZvyJAhcjgcOnTokGdPFgAQkLjiBADwiZiYGJe/7XbztzvDMMrWlZSUVHrb8PDwsv/bbDZJ5rC7yqSlpenQoUP629/+pk8++USjRo3SwIEDtWLFCjVs2LBOz8Gp/HP57rvvdN9992ny5MkV9k1KSvLKYwIA/IvACQDgF82bN5dkluXu0aOHJLkUiqiLuLg4jR49WqNHj9btt9+uoUOH6vTp0+rWrZuOHDmi/fv3V3rVKSUlRVu2bHFZt2XLFnXq1KksD6oyaWlpysrKUocOHbzSfgBA4CFwAgD4RcOGDXXddddpwYIFateunU6cOKEnn3yyzve7cOFCtW7dWj169JDdbtf777+vVq1aqUmTJhowYIBuvPFG3XbbbVq4cKE6dOigvXv3ymazaejQoXr00UfVq1cvzZ07V6NHj9a2bdv0yiuv6LXXXqv2MZ944gldd911ysjI0KRJkxQTE6OsrCytX79er7zySpW3cwaK3333nU6ePKmdO3cqIiJCqampdT4OAADvIscJAOA3S5YsUWlpqdLT0/XII4/ot7/9bZ3vMzY2Vs8++6x69uypXr166fDhw1q9enXZ0MAPPvhAvXr10pgxY5SamqrHH3+8LH8pLS1N7733npYtW6ZrrrlGM2fO1FNPPeVSGKIy3bp109///nft379f/fv3V48ePTRz5kxdeeWV1d6uR48e6tGjh3bs2KF3331XPXr00E9+8pM6HwMAgPfZjMsHlwMAAAAAKuCKEwAAAAC4QeAEAAAAAG4QOAEAAACAGwROAAAAAOAGgRMAAAAAuEHgBAAAAABuEDgBAAAAgBsETgAAAADgBoETAAAAALhB4AQAAAAAbhA4AQAAAIAb/x9TtO2r0RwbewAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting data for plotting\n",
    "x = df['run 1']\n",
    "y = df['run 2']\n",
    "\n",
    "# Creating the scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x, y, color='blue', alpha=0.5)\n",
    "plt.title('Scatter Plot: run score 1 vs. run score 2')\n",
    "plt.xlabel('run score 1')\n",
    "plt.ylabel('run score 2')\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 A Frequentist Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to construct a model that can predict which of the 16 skateboarders in the LCQ will secure a spot in the final. \n",
    "\n",
    "One approach to this is to construct a model for each skateboarder, utilize these models to simulate run scores and trick scores for every skateboarder, and then combine these simulations to simulate the LCQ as a whole. \n",
    "\n",
    "By simulating multiple LCQs, we can extract the top four skateboarders with the highest cumulative scores from each. \n",
    "Our prediction would then be the mode of these outcomes. \n",
    "\n",
    "**NOTE:** *Please note that this model assumes that the performances of the skateboarders are independent. For the sake of simplicity, we'll assume that the score for a particular run $Y_i$ and the score for a specific trick $X_i$ are independent for each skateboarder.*\n",
    "\n",
    "- For skateboarder $i$, we assume that all trick scores and run scores are independent and have identically distributed outcomes from $X_i$ and $Y_i$ respectively. \n",
    "\n",
    "- We can start by specifying a model for $X_i$ and $Y_i$. \n",
    "\n",
    "---\n",
    "\n",
    "From the observations in Task 1, a plausible model for $X_i$ is the following:\n",
    "$$\n",
    "X_i = \n",
    "\\begin{cases} \n",
    "0 & \\text{if } V_i = 0, \\\\ \n",
    "Z_i & \\text{if } V_i = 1,\n",
    "\\end{cases}\n",
    "$$\n",
    "where \n",
    "$$ V_i \\sim \\text{Ber}(\\theta_i), $$\n",
    "$$ Z_i \\sim \\text{Beta}(\\alpha_i, \\beta_i) $$\n",
    "and \n",
    "$$ V_i \\perp Z_i. $$\n",
    "It can be shown that\n",
    "$$ \n",
    "f_{X_i}(x_i | \\theta_i, \\alpha_i, \\beta_i) = (1-\\theta_i) \\mathbb{1}_{\\{x_i=0\\}} + \\theta_i f_{Z_i}(z_i).\n",
    "$$\n",
    "The choice $ V_i \\sim \\text{Ber}(\\theta_i) $ models the fact that a skateboarder receives a score of 0 if and only if they do not successfully land the trick. Meanwhile, the choice $ Z_i \\sim \\text{Beta}(\\alpha_i, \\beta_i) $ models that the score for a particular trick represents the portion of the trick that was \"perfect.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Provide a point estimate for each $\\theta_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANALYTICAL ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Bernoulli_distribution\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "We can attempt a ML point estimation for $\\theta_i$ since we know that $V_i$ follows a Bernoulli distribution with parameter $\\theta_i$.\n",
    "\n",
    "$$ V_i \\sim \\text{Ber}(\\theta_i) $$\n",
    "$$\n",
    "f_{V_i}\\left(\\theta_i\\right)=\\theta_i^{v_i}\\left(1-\\theta_i\\right)^{1-v_1}\n",
    "$$\n",
    "\n",
    "*Note: Parameter $\\theta_i$ for $\\text{Ber}(\\theta_i)$ has to be $\\theta_i \\in[0,1]$ we lake this since we normalized the scores.*\n",
    "\n",
    "$$\n",
    "\\log L\\left(\\theta \\mid v_j\\right)=\\log \\prod_i^n \\theta_i^{v_i}(1-\\theta_i)^{1-v_i}=\n",
    "$$\n",
    "$$\n",
    "=\\sum_{k=1}^n \\log \\theta_i^{v_k}(1-\\theta_i)^{1-x_k}=\\sum_{k=1}^n \\log \\theta_i^{v_k}+\\sum_{k=1}^n \\log \\left(1-\\theta_i\\right)^{1-v_k}=\n",
    "$$\n",
    "$$\n",
    "=\\log \\theta_i \\cdot \\sum_{k=1} V_k+\\log \\left(1-\\theta_i\\right) \\sum\\left(1-V_k\\right)\n",
    "$$\n",
    "\n",
    "*We can now attmpt to take a derivative.*\n",
    "\n",
    "$$\n",
    "L^{\\prime}\\left(\\theta_i \\mid v\\right)=\\frac{\\sum V_k}{\\theta_i}-\\frac{1}{1-\\theta_i}\\sum_{k=1}^n\\left(1-v_k\\right)=\\frac{\\sum_{k=1}^n v_k}{\\theta_i}-\\frac{\\left(n-\\sum_{k=1}^n v_k\\right)}{1-\\theta_i}\n",
    "$$\n",
    "\n",
    "*To find the critical point we set $L^{\\prime}\\left(\\theta_i \\mid v\\right)=0$*\n",
    "$$\n",
    "\\frac{\\sum_{k=1}^n v_k}{\\theta_i}-\\frac{\\left(n-\\sum_{k=1}^n v_k\\right)}{1-\\theta_i}=0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\sum_{k=1}^n v_k}{\\theta_i}-\\frac{\\left(n-\\sum_{k=1}^n v_k\\right)}{1-\\theta_i}=0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\sum_{k=1}^n v_k}{\\theta_i}=\\frac{\\left(n-\\sum_{k=1}^n v_k\\right)}{1-\\theta_i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^n v_k-\\theta_i \\sum_{k=1}^n v_k=\\theta_i n-\\theta_i\\sum_{k=1}^nv_k\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^n v_k=\\theta_i n\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_i=\\frac{\\sum_{k=1}^n v_k}{n}\n",
    "$$\n",
    "\n",
    "***We can see that this is just a sample mean.***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  theta_i\n",
      "0      Berger     0.50\n",
      "1        Papa     0.75\n",
      "2     Pudwill     0.00\n",
      "3      Shirai     0.50\n",
      "4        Mota     0.25\n",
      "..        ...      ...\n",
      "92      Hoban     0.50\n",
      "93    Hoefler     0.50\n",
      "94      Eaton     0.50\n",
      "95     Joslin     0.50\n",
      "96  Ribeiro G     0.75\n",
      "\n",
      "[97 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extracting data for plotting\n",
    "make_columns = ['make 1', 'make 2', 'make 3', 'make 4']\n",
    "\n",
    "df['total_made'] = df[make_columns].sum(axis=1)\n",
    "df['total_attempted'] = df[['trick 1', 'trick 2', 'trick 3', 'trick 4']].notna().sum(axis=1)\n",
    "df['theta_i'] = df['total_made'] / df['total_attempted']\n",
    "\n",
    "#print(df)\n",
    "\n",
    "print(df[['id', 'theta_i']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Colective $\\theta_i$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now I have $\\theta_i$ for each skateboarder at each location, but it would be nice to have just one $\\theta_i$ for each name.\n",
    "\n",
    "- Can i take and average of $\\theta_i$ to reresent the $\\theta_{itotal}$ for a specific skateboarder id?\n",
    "\n",
    "Concerns I have:\n",
    "\n",
    "-  Lose of information about the variability of $\\theta_i$.\n",
    "-  Each skateborder has an equal number of attempts at each location so its no weighted to favor one location.\n",
    "-  If the distribution of $\\theta_i$ values for a skateboarder is skewed, then the mean might not be the most representative measure. In that case, I would want to do median or mode...\n",
    "\n",
    "I'm I second year bachelors student and dont know any better, let's do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  theta_average\n",
      "0      Berger       0.166667\n",
      "1     Decenzo       0.437500\n",
      "2       Eaton       0.625000\n",
      "3         Foy       0.500000\n",
      "4        Fynn       0.500000\n",
      "5     Gustavo       0.400000\n",
      "6       Hoban       0.400000\n",
      "7     Hoefler       0.437500\n",
      "8    Horigome       0.562500\n",
      "9      Huston       0.375000\n",
      "10     Jordan       0.400000\n",
      "11     Joslin       0.450000\n",
      "12    Majerus       0.375000\n",
      "13    McClung       0.250000\n",
      "14     Midler       0.333333\n",
      "15      Milou       0.450000\n",
      "16       Mota       0.250000\n",
      "17   Oliveira       0.416667\n",
      "18    Oâ€™neill       0.250000\n",
      "19       Papa       0.437500\n",
      "20    Pudwill       0.250000\n",
      "21  Ribeiro C       0.250000\n",
      "22  Ribeiro G       0.541667\n",
      "23  Rodriguez       0.500000\n",
      "24   Santiago       0.083333\n",
      "25     Shirai       0.400000\n",
      "26     Silvas       0.375000\n",
      "27      Suciu       0.625000\n",
      "28       Wair       0.500000\n",
      "29     Wright       0.250000\n"
     ]
    }
   ],
   "source": [
    "# Group by 'id' and compute the mean of theta_i for each skateboarder\n",
    "theta_average = df.groupby('id')['theta_i'].mean().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "theta_average.columns = ['id', 'theta_average']\n",
    "\n",
    "# Print the results\n",
    "print(theta_average)\n",
    "\n",
    "#Okay, that's great! \n",
    "# Now I have this information, but I would like to save it into the main DataFrame file.\n",
    "# Merge the theta_average DataFrame with the original df on 'id'\n",
    "df = df.merge(theta_average, on='id', how='left')\n",
    "\n",
    "# Now the original df has an additional column 'theta_average'\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are there skateboarders for whom your chosen point estimate does not exist? \n",
    "- If so, suggest an alternative point estimate for these $\\theta_i$. \n",
    "- Justify your choices of point estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Creating results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round all float columns to 5 decimal places\n",
    "df = df.round(5)\n",
    "results_df = theta_average[['id', 'theta_average']]\n",
    "\n",
    "#print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***It's hard for me to see exactly what I'm doing, so I want to create a separate file named Datafile_Frequentist.csv***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Provide a point estimate for the parameters $\\left[\\alpha_i, \\beta_i\\right]^{\\mathrm{T}}$ for each skateboarder $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### ANALYTICAL ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Gamma_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Beta_distribution\n",
    "\n",
    "---\n",
    "\n",
    "For the Beta distribution:\n",
    "$$\n",
    "f\\left(z_i \\mid \\alpha_i, \\beta_i\\right)=\\frac{z_i^{\\alpha_i-1}\\left(1-z_i\\right)^{\\beta_i-1}}{B\\left(\\alpha_i, \\beta_i\\right)}\n",
    "$$\n",
    "where $B\\left(\\alpha_i, \\beta_i\\right)$ is the beta function, which acts as a normalization constant.\n",
    "\n",
    "From the provided data, we have scores for each trick when it's not zero. \n",
    "To estimate $\\alpha_i$ and $\\beta_i$, we can make use of the mean and variance properties of the Beta distribution.\n",
    "\n",
    "To the population mean and variance, we knwo from formula sheet:\n",
    "\n",
    "- Mean: $\\mu=\\frac{\\alpha_i}{\\alpha_i+\\beta_i}$\n",
    "- Variance: $\\sigma^2=\\frac{\\alpha_i \\beta_i}{\\left(\\alpha_i+\\beta_i\\right)^2\\left(\\alpha_i+\\beta_i+1\\right)}$\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{\\alpha}{\\alpha+\\beta} \\quad \\text { and } \\quad S^2 = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)} .\n",
    "$$\n",
    "Solving for $\\alpha$ and $\\beta$:\n",
    "$$\n",
    "\\beta = \\frac{\\alpha - \\alpha \\mu}{\\mu} = \\frac{\\alpha}{\\mu} - \\alpha .\n",
    "$$\n",
    "After substituting and simplifying, we find:\n",
    "$$\n",
    "\\alpha = \\mu\\left(\\frac{\\mu(1-\\mu)}{S^2}-1\\right) .\n",
    "$$\n",
    "Expressing $\\beta$ using $\\mu$ and $S^2$:\n",
    "$$\n",
    "\\beta = (1-\\mu)\\left(\\frac{\\mu(1-\\mu)}{S^2}-1\\right) .\n",
    "$$\n",
    "THence, we can derive the method of moment estimators for $\\alpha$ and $\\beta$ are:\n",
    "$$\n",
    "\\hat{\\alpha} = \\mu\\left(\\frac{\\mu(1-\\mu)}{S^2}-1\\right) \\text { and } \\hat{\\beta} = (1-\\mu)\\left(\\frac{\\mu(1-\\mu)}{S^2}-1\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "We can write:\n",
    "$$\n",
    "f\\left(x_i \\mid \\alpha, \\beta, V_i=1\\right) = f\\left(z_i \\mid \\alpha, \\beta\\right) = L\\left(\\alpha, \\beta \\mid V_i=1, X_i=x_i\\right)\n",
    "$$\n",
    "\n",
    "Lets rewrite the $\\mathrm{B}(\\alpha, \\beta)$ function:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{B}(\\alpha, \\beta)=\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}\n",
    "$$\n",
    "\n",
    "Now let's do the only thing we, God willing, know how to do: a ML point estimation.\n",
    "\n",
    "$$\n",
    "f_z(z \\mid \\alpha, \\beta)=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} z^{\\alpha-1}(1-z)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\log L(\\alpha, \\beta \\mid z)=\\log \\prod_{i=1}^n\\left(\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} z_i^{\\alpha-1}\\left(1-z_i\\right)^{\\beta-1}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "=n \\log \\left(\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)}\\right)+(\\alpha-1) \\sum_i^n \\log z_i+(\\beta-1) \\sum_{i=1}^n \\log \\left(1-z_i\\right)\n",
    "$$\n",
    "\n",
    "We take derivatives with respect to $\\alpha$ and $\\beta$.\n",
    "\n",
    "For the first term, using the properties of logarithms and the derivative of the Gamma function, $\\psi(z)=\\frac{d}{d z} \\log \\Gamma(z)$, this we found online...\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\alpha}=n \\psi(\\alpha+\\beta)-n \\psi(\\alpha)+\\sum_{i=1}^n \\log z_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\beta}=n \\psi(\\alpha+\\beta)-n \\psi(\\beta)+\\sum_i^n \\log \\left(1-z_i\\right)\n",
    "$$\n",
    "\n",
    "We can rewrite this as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\frac{\\partial L}{\\partial \\alpha}=\\psi(\\alpha)-\\psi(\\alpha+\\beta)-\\frac{1}{n} \\sum_{i=1}^n \\log \\left(z_i\\right) \\\\\n",
    "& \\frac{\\partial L}{\\partial \\beta}=\\psi(\\beta)-\\psi(\\alpha+\\beta)-\\frac{1}{n} \\sum_{i=1}^n \\log \\left(1-z_i\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "*I guess this is the equivalent of running headfirst into a wall...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUMERICAL ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_tricks(tricks):\n",
    "    # This function aggregates the tricks by filtering out zero values\n",
    "    return list(tricks[tricks != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                             tricks\n",
      "0      Berger                                        [0.7, 0.76]\n",
      "1     Decenzo         [0.78, 0.86, 0.87, 0.86, 0.78, 0.93, 0.71]\n",
      "2       Eaton                     [0.75, 0.84, 0.84, 0.77, 0.75]\n",
      "3         Foy                  [0.8, 0.79, 0.83, 0.9, 0.88, 0.9]\n",
      "4        Fynn                [0.88, 0.9, 0.76, 0.74, 0.86, 0.82]\n",
      "5     Gustavo     [0.83, 0.77, 0.8, 0.8, 0.74, 0.83, 0.88, 0.76]\n",
      "6       Hoban   [0.82, 0.91, 0.86, 0.86, 0.92, 0.89, 0.88, 0.88]\n",
      "7     Hoefler         [0.85, 0.73, 0.78, 0.67, 0.78, 0.87, 0.75]\n",
      "8    Horigome  [0.88, 0.95, 0.87, 0.95, 0.84, 0.95, 0.83, 0.9...\n",
      "9      Huston                                 [0.86, 0.88, 0.92]\n",
      "10     Jordan       [0.84, 0.9, 0.88, 0.9, 0.9, 0.7, 0.88, 0.91]\n",
      "11     Joslin  [0.84, 0.81, 0.79, 0.85, 0.85, 0.86, 0.83, 0.8...\n",
      "12    Majerus                                  [0.79, 0.4, 0.36]\n",
      "13    McClung                                             [0.45]\n",
      "14     Midler                           [0.79, 0.73, 0.87, 0.84]\n",
      "15      Milou  [0.86, 0.86, 0.86, 0.83, 0.75, 0.88, 0.9, 0.9,...\n",
      "16       Mota                                 [0.78, 0.69, 0.87]\n",
      "17   Oliveira                      [0.71, 0.82, 0.83, 0.8, 0.81]\n",
      "18    Oâ€™neill                                 [0.83, 0.85, 0.85]\n",
      "19       Papa          [0.72, 0.89, 0.73, 0.84, 0.65, 0.8, 0.82]\n",
      "20    Pudwill                                  [0.56, 0.55, 0.7]\n",
      "21  Ribeiro C                                  [0.79, 0.8, 0.74]\n",
      "22  Ribeiro G  [0.87, 0.92, 0.88, 0.92, 0.91, 0.92, 0.81, 0.9...\n",
      "23  Rodriguez                            [0.7, 0.73, 0.83, 0.74]\n",
      "24   Santiago                                             [0.47]\n",
      "25     Shirai    [0.75, 0.96, 0.93, 0.9, 0.86, 0.92, 0.93, 0.93]\n",
      "26     Silvas                                  [0.81, 0.8, 0.83]\n",
      "27      Suciu                     [0.86, 0.78, 0.76, 0.72, 0.72]\n",
      "28       Wair                                       [0.84, 0.63]\n",
      "29     Wright                                             [0.72]\n"
     ]
    }
   ],
   "source": [
    "trick_columns = ['trick 1', 'trick 2', 'trick 3', 'trick 4']\n",
    "\n",
    "# Group by 'id' and aggregate tricks for each skateboarder\n",
    "all_tricks_df = df.melt(id_vars='id', value_vars=trick_columns)\\\n",
    "                  .groupby('id')['value']\\\n",
    "                  .agg(aggregate_tricks)\\\n",
    "                  .reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "all_tricks_df.columns = ['id', 'tricks']\n",
    "\n",
    "# Print the result\n",
    "print(all_tricks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                             tricks\n",
      "0      Berger  [0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.76, 0.0, 0.0,...\n",
      "1     Decenzo  [0.78, 0.86, 0.87, 0.0, 0.0, 0.0, 0.0, 0.86, 0...\n",
      "2       Eaton      [0.75, 0.0, 0.84, 0.84, 0.77, 0.75, 0.0, 0.0]\n",
      "3         Foy  [0.8, 0.0, 0.79, 0.83, 0.9, 0.0, 0.88, 0.9, 0....\n",
      "4        Fynn  [0.88, 0.0, 0.0, 0.9, 0.76, 0.74, 0.0, 0.86, 0...\n",
      "5     Gustavo  [0.83, 0.0, 0.77, 0.8, 0.8, 0.74, 0.0, 0.0, 0....\n",
      "6       Hoban  [0.0, 0.82, 0.91, 0.86, 0.86, 0.0, 0.92, 0.89,...\n",
      "7     Hoefler  [0.0, 0.85, 0.73, 0.78, 0.67, 0.0, 0.0, 0.0, 0...\n",
      "8    Horigome  [0.88, 0.95, 0.87, 0.95, 0.0, 0.0, 0.0, 0.0, 0...\n",
      "9      Huston        [0.86, 0.0, 0.88, 0.0, 0.0, 0.0, 0.0, 0.92]\n",
      "10     Jordan  [0.0, 0.0, 0.84, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "11     Joslin  [0.0, 0.84, 0.0, 0.81, 0.79, 0.85, 0.85, 0.86,...\n",
      "12    Majerus         [0.79, 0.4, 0.0, 0.0, 0.0, 0.0, 0.36, 0.0]\n",
      "13    McClung                              [0.45, 0.0, 0.0, 0.0]\n",
      "14     Midler  [0.0, 0.79, 0.0, 0.0, 0.0, 0.73, 0.87, 0.0, 0....\n",
      "15      Milou  [0.86, 0.86, 0.0, 0.86, 0.83, 0.75, 0.0, 0.88,...\n",
      "16       Mota  [0.78, 0.0, 0.69, 0.0, 0.87, 0.0, 0.0, 0.0, 0....\n",
      "17   Oliveira  [0.0, 0.0, 0.0, 0.0, 0.0, 0.71, 0.0, 0.82, 0.8...\n",
      "18    Oâ€™neill  [0.83, 0.85, 0.0, 0.0, 0.0, 0.0, 0.85, 0.0, 0....\n",
      "19       Papa  [0.72, 0.89, 0.73, 0.0, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "20    Pudwill  [0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "21  Ribeiro C  [0.79, 0.8, 0.74, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "22  Ribeiro G  [0.0, 0.87, 0.92, 0.0, 0.0, 0.0, 0.88, 0.0, 0....\n",
      "23  Rodriguez        [0.7, 0.73, 0.0, 0.0, 0.83, 0.74, 0.0, 0.0]\n",
      "24   Santiago  [0.0, 0.0, 0.47, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "25     Shirai  [0.75, 0.96, 0.0, 0.93, 0.0, 0.0, 0.9, 0.0, 0....\n",
      "26     Silvas         [0.81, 0.8, 0.83, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "27      Suciu      [0.86, 0.78, 0.76, 0.72, 0.0, 0.0, 0.72, 0.0]\n",
      "28       Wair                             [0.0, 0.0, 0.84, 0.63]\n",
      "29     Wright                              [0.0, 0.0, 0.72, 0.0]\n"
     ]
    }
   ],
   "source": [
    "trick_columns = ['trick 1', 'trick 2', 'trick 3', 'trick 4']\n",
    "# Group by 'id' and aggregate tricks for each skateboarder\n",
    "all_tricks_df_with_zeroes = df.melt(id_vars='id', value_vars=trick_columns)\\\n",
    "                  .groupby('id')['value']\\\n",
    "                  .apply(list)\\\n",
    "                  .reset_index()\n",
    "# Rename the columns for clarity\n",
    "all_tricks_df_with_zeroes.columns = ['id', 'tricks']\n",
    "# Print the result\n",
    "print(all_tricks_df_with_zeroes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Moment estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moment_estimators (data):\n",
    "    moment_estimators=[]\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean = np.mean(data)\n",
    "\n",
    "    # Calculate variance\n",
    "    variance = np.var(data, ddof=1)\n",
    "    # ddof=1 means that we want to calculate the sample variance\n",
    "    #-----------------------------------\n",
    "    \n",
    "    # Calculate a1\n",
    "    a1 = mean * (mean * (1 - mean) / variance - 1)\n",
    "    moment_estimators.append(a1)\n",
    "    \n",
    "    # Calculate b1\n",
    "    b1 = (1 - mean) * (mean * (1 - mean) / variance - 1)\n",
    "    moment_estimators.append(b1)\n",
    "    \n",
    "    return moment_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Math and gameplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's do gradient descent and try to solve it numerically.*\n",
    "\n",
    "Basic game plan:\n",
    "\n",
    "1. ***Initialization:*** We choose initial values for $\\alpha$ and $\\beta$ at random or choose something sensible via prior knowledge.\n",
    "\n",
    "2. ***Compute Gradient:*** At each iteration, we compute the gradient of the log-likelihood function with respect to $\\alpha$ and $\\beta$.\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\alpha} \\text { and } \\frac{\\partial L}{\\partial \\beta}\n",
    "$$\n",
    "3. ***Update Parameters:*** Update $\\alpha$ and $\\beta$ using the gradients:\n",
    "Where $\\eta$ is the learning rate. It's a hyperparameter that you'll need to set. A smaller value will make the optimization more stable but slower, while a larger value will speed up the optimization but can make it overshoot or even diverge.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\alpha=\\alpha+\\eta \\frac{\\partial L}{\\partial \\alpha} \\\\\n",
    "& \\beta=\\beta+\\eta \\frac{\\partial L}{\\partial \\beta}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "4. ***Convergence Check***: Repeat steps 2 and 3 until we get change in the log-likelihood between iterations is below a predetermined threshold, or until a set number of iterations is reached.\n",
    "\n",
    "5. ***Output***: Once convergence is achieved, the values of $\\alpha$ and $\\beta$ are your MLEs.\n",
    "\n",
    "6.  ***Invoke the name of Olof***: This will remind you of how this is simmilar to what we did in SF1550."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initial guess use method of moments***\n",
    "\n",
    "- Method of moments estimator we equate the population moments with the sample moments specifically the first and second moments.\n",
    "- Then we solve for $\\alpha$ and $\\beta$ to get our moment estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient(alpha_beta, data):\n",
    "    alpha, beta = alpha_beta\n",
    "    n = len(data)\n",
    "    \n",
    "    psi_alpha_plus_beta = sp.psi(alpha + beta)\n",
    "    psi_alpha = sp.psi(alpha)\n",
    "    psi_beta = sp.psi(beta)\n",
    "    \n",
    "    grad_alpha = psi_alpha - psi_alpha_plus_beta - (1/n)*np.sum(np.log(data))\n",
    "    grad_beta = psi_beta - psi_alpha_plus_beta - (1/n)*np.sum(np.log(1 - data))\n",
    "        \n",
    "    return np.array([grad_alpha, grad_beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graddes(initialization, stepsize, num_iter, data):\n",
    "    thetas = [initialization]\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        thetas = thetas + [thetas[-1] - (stepsize)*gradient(thetas[-1], data)]\n",
    "        \n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_method(samps):\n",
    "    \n",
    "    initialization = get_moment_estimators (samps)\n",
    "    G = graddes(initialization, 0.003, 100, samps)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id   alpha    beta\n",
      "0      Berger   79.20   29.29\n",
      "1     Decenzo   20.84    4.36\n",
      "2       Eaton   60.17   15.99\n",
      "3         Foy   42.85    7.56\n",
      "4        Fynn   26.94    5.65\n",
      "5     Gustavo   61.71   15.31\n",
      "6       Hoban   94.13   13.14\n",
      "7     Hoefler   27.77    8.03\n",
      "8    Horigome   30.97    3.31\n",
      "9      Huston   94.58   12.09\n",
      "10     Jordan   20.07    3.17\n",
      "11     Joslin  228.44   45.32\n",
      "12    Majerus    1.77    1.66\n",
      "13    McClung     NaN     NaN\n",
      "14     Midler   32.59    7.77\n",
      "15      Milou   33.18    6.16\n",
      "16       Mota   15.74    4.44\n",
      "17   Oliveira   54.94   14.26\n",
      "18    Oâ€™neill  834.83  155.09\n",
      "19       Papa   19.02    5.41\n",
      "20    Pudwill   19.93   13.10\n",
      "21  Ribeiro C  129.59   37.27\n",
      "22  Ribeiro G   36.93    5.11\n",
      "23  Rodriguez   44.13   14.71\n",
      "24   Santiago     NaN     NaN\n",
      "25     Shirai   17.90    2.04\n",
      "26     Silvas  528.40  121.27\n",
      "27      Suciu   40.45   12.22\n",
      "28       Wair    5.76    2.08\n",
      "29     Wright     NaN     NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:3715: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\villi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for index, row in all_tricks_df.iterrows():\n",
    "    samps = np.array(row['tricks'])\n",
    "    alpha_beta = get_moment_estimators(samps)\n",
    "    \n",
    "    all_tricks_df.at[index, 'alpha'] = round(alpha_beta[0],2)\n",
    "    all_tricks_df.at[index, 'beta'] = round(alpha_beta[1],2)\n",
    "\n",
    "print(all_tricks_df[['id', 'alpha', 'beta']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Newton-Raphson or Gauss-Newton method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Math and gameplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "& \\frac{\\partial L}{\\partial \\alpha}=\\psi(\\alpha)-\\psi(\\alpha+\\beta)-\\frac{1}{n} \\sum_{i=1}^n \\log \\left(z_i\\right) \\\\\n",
    "& \\frac{\\partial L}{\\partial \\beta}=\\psi(\\beta)-\\psi(\\alpha+\\beta)-\\frac{1}{n} \\sum_{i=1}^n \\log \\left(1-z_i\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "J=\\left|\\begin{array}{ll}\n",
    "\\psi^{\\prime}(\\alpha)-\\psi^{\\prime}(\\alpha+\\beta) & -\\psi^{\\prime}(\\alpha+\\beta) \\\\\n",
    "-\\psi^{\\prime}(\\alpha+\\beta)  & \\psi^{\\prime}(\\beta)-\\psi^{\\prime}(\\alpha+\\beta)\n",
    "\\end{array}\\right|\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{l}\n",
    "\\alpha \\\\\n",
    "\\beta\n",
    "\\end{array}\\right]_{\\text{NM}}=\\left[\\begin{array}{l}\n",
    "\\alpha \\\\\n",
    "\\beta\n",
    "\\end{array}\\right]_N-J^{-1}\\left(\\left[\\begin{array}{l}\n",
    "\\alpha \\\\\n",
    "\\beta\n",
    "\\end{array}\\right]_N\\right)\\left[\\begin{array}{l}\n",
    "f_1((\\alpha, \\beta)_N) \\\\\n",
    "f_2((\\alpha, \\beta)_N)\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "We repeat this untile convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gauss_Raphson_method (data , tolerance=1e-6, max_iter=1000):\n",
    "    \n",
    "    alpha_beta = get_moment_estimators(data)\n",
    "    alpha, beta = alpha_beta\n",
    "    \n",
    "    n = len(data)\n",
    "    \n",
    "    alpha_0, beta_0=alpha,beta\n",
    "\n",
    "    theta = np.array([alpha_0, beta_0])\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "\n",
    "        f = np.array([\n",
    "            sp.psi(theta[0]) - sp.psi(np.sum(theta)) - np.mean(np.log(data)),\n",
    "            sp.psi(theta[1]) - sp.psi(np.sum(theta)) - np.mean(np.log(1 - data))\n",
    "        ])\n",
    "\n",
    "        J = np.linalg.inv(np.array([\n",
    "            [sp.polygamma(1, (theta[0])) - sp.polygamma(1, np.sum(theta)), -sp.polygamma(1, np.sum(theta))],\n",
    "            [-sp.polygamma(1, np.sum(theta)), sp.polygamma(1, theta[1]) - sp.polygamma(1, np.sum(theta))]\n",
    "        ]))\n",
    "\n",
    "        # Newton-Raphson update\n",
    "        J_inv = np.linalg.inv(J)\n",
    "        theta = theta - J_inv @ f\n",
    "\n",
    "        if np.linalg.norm(f) <= tolerance:\n",
    "            return theta\n",
    "    \n",
    "    return theta\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  alpha_trick  beta_trick\n",
      "0      Berger        79.17       29.40\n",
      "1     Decenzo        20.84        4.41\n",
      "2       Eaton        60.15       16.06\n",
      "3         Foy        42.84        7.64\n",
      "4        Fynn        26.92        5.74\n",
      "5     Gustavo        61.71       15.33\n",
      "6       Hoban        94.12       13.21\n",
      "7     Hoefler        27.75        8.08\n",
      "8    Horigome        30.96        3.37\n",
      "9      Huston        94.56       12.22\n",
      "10     Jordan        20.06        3.36\n",
      "11     Joslin       228.44       45.35\n",
      "12    Majerus         3.01        2.73\n",
      "13    McClung         3.01        2.73\n",
      "14     Midler        32.56        7.89\n",
      "15      Milou        33.16        6.27\n",
      "16       Mota        15.73        4.58\n",
      "17   Oliveira        54.91       14.39\n",
      "18    Oâ€™neill       834.83      155.09\n",
      "19       Papa        19.00        5.47\n",
      "20    Pudwill        19.90       13.15\n",
      "21  Ribeiro C       129.58       37.33\n",
      "22  Ribeiro G        36.92        5.20\n",
      "23  Rodriguez        44.11       14.77\n",
      "24   Santiago        44.11       14.77\n",
      "25     Shirai        17.90        2.22\n",
      "26     Silvas       528.39      121.28\n",
      "27      Suciu        40.44       12.25\n",
      "28       Wair         6.20        2.44\n",
      "29     Wright         6.20        2.44\n"
     ]
    }
   ],
   "source": [
    "for index, row in all_tricks_df.iterrows():\n",
    "    samps = np.array(row['tricks'])\n",
    "    \n",
    "    if len(samps) <= 1:\n",
    "        samps = np.array(all_tricks_df.loc[index, 'tricks'])\n",
    "    else:\n",
    "        try:\n",
    "            alpha_beta = Gauss_Raphson_method(samps)\n",
    "        except:\n",
    "            alpha_beta = get_moment_estimators(samps)\n",
    "            \n",
    "    all_tricks_df.at[index, 'alpha_trick'] = round(alpha_beta[0],2)\n",
    "    all_tricks_df.at[index, 'beta_trick'] = round(alpha_beta[1],2)\n",
    "\n",
    "print(all_tricks_df[['id', 'alpha_trick', 'beta_trick']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adding results to the results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  theta_average  alpha_trick  beta_trick\n",
      "0      Berger       0.166667        79.17       29.40\n",
      "1     Decenzo       0.437500        20.84        4.41\n",
      "2       Eaton       0.625000        60.15       16.06\n",
      "3         Foy       0.500000        42.84        7.64\n",
      "4        Fynn       0.500000        26.92        5.74\n",
      "5     Gustavo       0.400000        61.71       15.33\n",
      "6       Hoban       0.400000        94.12       13.21\n",
      "7     Hoefler       0.437500        27.75        8.08\n",
      "8    Horigome       0.562500        30.96        3.37\n",
      "9      Huston       0.375000        94.56       12.22\n",
      "10     Jordan       0.400000        20.06        3.36\n",
      "11     Joslin       0.450000       228.44       45.35\n",
      "12    Majerus       0.375000         3.01        2.73\n",
      "13    McClung       0.250000         3.01        2.73\n",
      "14     Midler       0.333333        32.56        7.89\n",
      "15      Milou       0.450000        33.16        6.27\n",
      "16       Mota       0.250000        15.73        4.58\n",
      "17   Oliveira       0.416667        54.91       14.39\n",
      "18    Oâ€™neill       0.250000       834.83      155.09\n",
      "19       Papa       0.437500        19.00        5.47\n",
      "20    Pudwill       0.250000        19.90       13.15\n",
      "21  Ribeiro C       0.250000       129.58       37.33\n",
      "22  Ribeiro G       0.541667        36.92        5.20\n",
      "23  Rodriguez       0.500000        44.11       14.77\n",
      "24   Santiago       0.083333        44.11       14.77\n",
      "25     Shirai       0.400000        17.90        2.22\n",
      "26     Silvas       0.375000       528.39      121.28\n",
      "27      Suciu       0.625000        40.44       12.25\n",
      "28       Wair       0.500000         6.20        2.44\n",
      "29     Wright       0.250000         6.20        2.44\n"
     ]
    }
   ],
   "source": [
    "results_df['alpha_trick'] = all_tricks_df['alpha_trick']\n",
    "results_df['beta_trick'] = all_tricks_df['beta_trick']\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in all_tricks_df.iterrows():\n",
    "#    samps = stats.beta.rvs(size=500, a=row['alpha'], b=row['beta'], scale=1)\n",
    "#    plt.figure()\n",
    "#    plt.hist(samps)\n",
    "#    plt.title(row['id'])\n",
    "#    plt.xlabel('Score')\n",
    "#    plt.ylabel('Frequency')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Propose a model for $Y_i$ and provide a point estimate for the parameters of your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                               runs\n",
      "0      Berger                [0.5, 0.22, 0.61, 0.11, 0.42, 0.41]\n",
      "1     Decenzo    [0.46, 0.83, 0.69, 0.31, 0.5, 0.58, 0.85, 0.54]\n",
      "2       Eaton                           [0.75, 0.69, 0.79, 0.72]\n",
      "3         Foy                 [0.54, 0.45, 0.1, 0.49, 0.59, 0.6]\n",
      "4        Fynn                [0.59, 0.6, 0.36, 0.68, 0.29, 0.38]\n",
      "5     Gustavo  [0.84, 0.16, 0.77, 0.59, 0.28, 0.12, 0.89, 0.8...\n",
      "6       Hoban  [0.35, 0.75, 0.41, 0.51, 0.62, 0.9, 0.68, 0.78...\n",
      "7     Hoefler   [0.79, 0.68, 0.85, 0.84, 0.69, 0.71, 0.03, 0.57]\n",
      "8    Horigome    [0.74, 0.63, 0.82, 0.9, 0.76, 0.91, 0.87, 0.73]\n",
      "9      Huston                           [0.78, 0.55, 0.86, 0.91]\n",
      "10     Jordan  [0.73, 0.7, 0.84, 0.77, 0.26, 0.9, 0.9, 0.86, ...\n",
      "11     Joslin  [0.68, 0.48, 0.73, 0.7, 0.68, 0.79, 0.85, 0.88...\n",
      "12    Majerus                            [0.4, 0.69, 0.09, 0.48]\n",
      "13    McClung                                        [0.31, 0.3]\n",
      "14     Midler                [0.81, 0.8, 0.63, 0.74, 0.01, 0.68]\n",
      "15      Milou  [0.78, 0.4, 0.68, 0.92, 0.69, 0.86, 0.68, 0.74...\n",
      "16       Mota                [0.38, 0.81, 0.34, 0.4, 0.38, 0.51]\n",
      "17   Oliveira                [0.84, 0.48, 0.5, 0.47, 0.72, 0.42]\n",
      "18    Oâ€™neill               [0.87, 0.69, 0.11, 0.09, 0.75, 0.19]\n",
      "19       Papa    [0.37, 0.72, 0.78, 0.38, 0.7, 0.35, 0.13, 0.66]\n",
      "20    Pudwill                [0.2, 0.18, 0.27, 0.13, 0.21, 0.44]\n",
      "21  Ribeiro C               [0.69, 0.72, 0.14, 0.66, 0.76, 0.28]\n",
      "22  Ribeiro G  [0.81, 0.67, 0.75, 0.75, 0.8, 0.85, 0.57, 0.91...\n",
      "23  Rodriguez                            [0.7, 0.47, 0.55, 0.21]\n",
      "24   Santiago               [0.55, 0.19, 0.61, 0.41, 0.39, 0.14]\n",
      "25     Shirai  [0.79, 0.91, 0.63, 0.47, 0.65, 0.7, 0.92, 0.67...\n",
      "26     Silvas                           [0.62, 0.68, 0.02, 0.58]\n",
      "27      Suciu                           [0.31, 0.79, 0.65, 0.85]\n",
      "28       Wair                                       [0.37, 0.79]\n",
      "29     Wright                                        [0.3, 0.28]\n"
     ]
    }
   ],
   "source": [
    "#Create all runs.\n",
    "def aggregate_runs(runs):\n",
    "    # This function aggregates the runs by filtering out zero values\n",
    "    return list(runs[runs != 0])\n",
    "\n",
    "# Assuming the runs are stored in columns named 'run1', 'run2', 'run3', etc.\n",
    "run_columns = ['run 1', 'run 2']  # Add more columns if needed\n",
    "\n",
    "# Group by 'id' and aggregate runs for each skateboarder\n",
    "all_runs_df = df.melt(id_vars='id', value_vars=run_columns)\\\n",
    "                  .groupby('id')['value']\\\n",
    "                  .agg(aggregate_runs)\\\n",
    "                  .reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "all_runs_df.columns = ['id', 'runs']\n",
    "\n",
    "# Print the result\n",
    "print(all_runs_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  alpha_run  beta_run\n",
      "0      Berger       2.46      4.07\n",
      "1     Decenzo       3.91      2.66\n",
      "2       Eaton      77.48     27.64\n",
      "3         Foy       2.80      3.46\n",
      "4        Fynn       4.45      4.75\n",
      "5     Gustavo       1.57      1.18\n",
      "6       Hoban       3.63      2.09\n",
      "7     Hoefler       1.41      1.02\n",
      "8    Horigome      12.91      3.39\n",
      "9      Huston       5.17      1.65\n",
      "10     Jordan       4.05      1.53\n",
      "11     Joslin       9.48      3.37\n",
      "12    Majerus       1.68      2.48\n",
      "13    McClung    1292.74   2945.76\n",
      "14     Midler      28.00     22.08\n",
      "15      Milou       5.96      2.62\n",
      "16       Mota       3.61      3.91\n",
      "17   Oliveira       4.62      3.41\n",
      "18    Oâ€™neill       1.00      1.26\n",
      "19       Papa       2.35      2.30\n",
      "20    Pudwill       3.58     10.95\n",
      "21  Ribeiro C       2.07      1.86\n",
      "22  Ribeiro G       5.04      2.01\n",
      "23  Rodriguez       3.05      3.31\n",
      "24   Santiago       2.47      4.00\n",
      "25     Shirai       1.57      1.09\n",
      "26     Silvas       7.58     15.78\n",
      "27      Suciu       3.23      1.81\n",
      "28       Wair       3.08      2.23\n",
      "29     Wright     298.27    730.23\n"
     ]
    }
   ],
   "source": [
    "for index, row in all_runs_df.iterrows():\n",
    "    samps = np.array(row['runs'])\n",
    "    alpha_beta = Gauss_Raphson_method(samps)\n",
    "    \n",
    "    all_runs_df.at[index, 'alpha_run'] = round(alpha_beta[0],2)\n",
    "    all_runs_df.at[index, 'beta_run'] = round(alpha_beta[1],2)\n",
    "\n",
    "print(all_runs_df[['id', 'alpha_run', 'beta_run']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Justify your choices for the model and point estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adding results to the results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  theta_average  alpha_trick  beta_trick  alpha_run  beta_run\n",
      "0      Berger       0.166667        79.17       29.40       2.46      4.07\n",
      "1     Decenzo       0.437500        20.84        4.41       3.91      2.66\n",
      "2       Eaton       0.625000        60.15       16.06      77.48     27.64\n",
      "3         Foy       0.500000        42.84        7.64       2.80      3.46\n",
      "4        Fynn       0.500000        26.92        5.74       4.45      4.75\n",
      "5     Gustavo       0.400000        61.71       15.33       1.57      1.18\n",
      "6       Hoban       0.400000        94.12       13.21       3.63      2.09\n",
      "7     Hoefler       0.437500        27.75        8.08       1.41      1.02\n",
      "8    Horigome       0.562500        30.96        3.37      12.91      3.39\n",
      "9      Huston       0.375000        94.56       12.22       5.17      1.65\n",
      "10     Jordan       0.400000        20.06        3.36       4.05      1.53\n",
      "11     Joslin       0.450000       228.44       45.35       9.48      3.37\n",
      "12    Majerus       0.375000         3.01        2.73       1.68      2.48\n",
      "13    McClung       0.250000         3.01        2.73    1292.74   2945.76\n",
      "14     Midler       0.333333        32.56        7.89      28.00     22.08\n",
      "15      Milou       0.450000        33.16        6.27       5.96      2.62\n",
      "16       Mota       0.250000        15.73        4.58       3.61      3.91\n",
      "17   Oliveira       0.416667        54.91       14.39       4.62      3.41\n",
      "18    Oâ€™neill       0.250000       834.83      155.09       1.00      1.26\n",
      "19       Papa       0.437500        19.00        5.47       2.35      2.30\n",
      "20    Pudwill       0.250000        19.90       13.15       3.58     10.95\n",
      "21  Ribeiro C       0.250000       129.58       37.33       2.07      1.86\n",
      "22  Ribeiro G       0.541667        36.92        5.20       5.04      2.01\n",
      "23  Rodriguez       0.500000        44.11       14.77       3.05      3.31\n",
      "24   Santiago       0.083333        44.11       14.77       2.47      4.00\n",
      "25     Shirai       0.400000        17.90        2.22       1.57      1.09\n",
      "26     Silvas       0.375000       528.39      121.28       7.58     15.78\n",
      "27      Suciu       0.625000        40.44       12.25       3.23      1.81\n",
      "28       Wair       0.500000         6.20        2.44       3.08      2.23\n",
      "29     Wright       0.250000         6.20        2.44     298.27    730.23\n"
     ]
    }
   ],
   "source": [
    "results_df['alpha_run'] = all_runs_df['alpha_run']\n",
    "results_df['beta_run'] = all_runs_df['beta_run']\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show my Paramter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  theta_average  alpha_trick  beta_trick  alpha_run  beta_run\n",
      "0      Berger       0.166667        79.17       29.40       2.46      4.07\n",
      "1     Decenzo       0.437500        20.84        4.41       3.91      2.66\n",
      "2       Eaton       0.625000        60.15       16.06      77.48     27.64\n",
      "3         Foy       0.500000        42.84        7.64       2.80      3.46\n",
      "4        Fynn       0.500000        26.92        5.74       4.45      4.75\n",
      "5     Gustavo       0.400000        61.71       15.33       1.57      1.18\n",
      "6       Hoban       0.400000        94.12       13.21       3.63      2.09\n",
      "7     Hoefler       0.437500        27.75        8.08       1.41      1.02\n",
      "8    Horigome       0.562500        30.96        3.37      12.91      3.39\n",
      "9      Huston       0.375000        94.56       12.22       5.17      1.65\n",
      "10     Jordan       0.400000        20.06        3.36       4.05      1.53\n",
      "11     Joslin       0.450000       228.44       45.35       9.48      3.37\n",
      "12    Majerus       0.375000         3.01        2.73       1.68      2.48\n",
      "13    McClung       0.250000         3.01        2.73    1292.74   2945.76\n",
      "14     Midler       0.333333        32.56        7.89      28.00     22.08\n",
      "15      Milou       0.450000        33.16        6.27       5.96      2.62\n",
      "16       Mota       0.250000        15.73        4.58       3.61      3.91\n",
      "17   Oliveira       0.416667        54.91       14.39       4.62      3.41\n",
      "18    Oâ€™neill       0.250000       834.83      155.09       1.00      1.26\n",
      "19       Papa       0.437500        19.00        5.47       2.35      2.30\n",
      "20    Pudwill       0.250000        19.90       13.15       3.58     10.95\n",
      "21  Ribeiro C       0.250000       129.58       37.33       2.07      1.86\n",
      "22  Ribeiro G       0.541667        36.92        5.20       5.04      2.01\n",
      "23  Rodriguez       0.500000        44.11       14.77       3.05      3.31\n",
      "24   Santiago       0.083333        44.11       14.77       2.47      4.00\n",
      "25     Shirai       0.400000        17.90        2.22       1.57      1.09\n",
      "26     Silvas       0.375000       528.39      121.28       7.58     15.78\n",
      "27      Suciu       0.625000        40.44       12.25       3.23      1.81\n",
      "28       Wair       0.500000         6.20        2.44       3.08      2.23\n",
      "29     Wright       0.250000         6.20        2.44     298.27    730.23\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Simulate LCQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your model for $[X_i, Y_i]^T$ to simulate $5000$ LCQs and for each simulation extract the four skateboarders $\\mathbf{W} = [W_1, W_2, W_3, W_4]^T$ with the highest total scores. \n",
    "- What is the mode for $W_1, \\ldots, W_{5000}$? \n",
    "\n",
    "The actual winners for the LCQ are Gustavo, Hoban, Eaton, and Decenzo. \n",
    "\n",
    "- How many of the actual winners are predicted by the mode? \n",
    "- What is the estimated probability of the actual winners based on your simulations? By the mode?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_trick(theta):\n",
    "    made=bool(np.random.binomial(1, theta))\n",
    "    return made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trick_score(alpha, beta):\n",
    "    return stats.beta.rvs(alpha, beta, size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_score(alpha, beta):\n",
    "    return stats.beta.rvs(alpha, beta, size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_score(trick_scores, run_scores):\n",
    "    return max(run_scores) + sorted(trick_scores)[-1] + sorted(trick_scores)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_my_df(new_lcq_df):\n",
    "    sorted_df = new_lcq_df.sort_values(by='total score', ascending=False)\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lcq(results_df):\n",
    "    #del new_lcq_df\n",
    "    new_lcq_df = pd.DataFrame(columns=[\"id\", \"run 1\", \"run 2\", \"trick 1\", \"trick 2\", \"trick 3\", \"trick 4\"])\n",
    "    \n",
    "    for index, row in results_df.iterrows():\n",
    "        #theta_average  alpha_trick  beta_trick  alpha_run  beta_run\n",
    "        theta_average=row['theta_average']\n",
    "        alpha_trick=row['alpha_trick']\n",
    "        beta_trick=row['beta_trick']    \n",
    "        alpha_run=row['alpha_run']\n",
    "        beta_run=row['beta_run']\n",
    "        \n",
    "        new_lcq_df.at[index, \"id\"]=row['id']\n",
    "        \n",
    "        for _ in range(4):\n",
    "            if successful_trick(theta_average):\n",
    "                trick=trick_score(alpha_trick, beta_trick)\n",
    "            else:\n",
    "                trick=0\n",
    "            new_lcq_df.at[index, f\"trick {_+1}\"] = round(trick,1)\n",
    "        \n",
    "        for _ in range(2):\n",
    "            run=run_score(alpha_run, beta_run)\n",
    "            new_lcq_df.at[index, f\"run {_+1}\"] = round(run,1)\n",
    "        \n",
    "        total_score_value=total_score(new_lcq_df.loc[index, ['trick 1', 'trick 2', 'trick 3', 'trick 4']], new_lcq_df.loc[index, ['run 1', 'run 2']]) \n",
    "        new_lcq_df.at[index, \"total score\"]=round(total_score_value,1)\n",
    "    \n",
    "    return new_lcq_df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id run 1 run 2 trick 1 trick 2 trick 3 trick 4  total score\n",
      "0      Berger   0.1   0.4     0.8       0     0.7       0          1.9\n",
      "1     Decenzo   0.9   0.6       0       0       0     0.8          1.7\n",
      "2       Eaton   0.7   0.8     0.8     0.8       0     0.8          2.4\n",
      "3         Foy   0.6   0.7       0       0       0     0.8          1.5\n",
      "4        Fynn   0.2   0.5       0     0.8       0     0.8          2.1\n",
      "5     Gustavo   0.9   0.7       0     0.8       0       0          1.7\n",
      "6       Hoban   0.6   0.7     0.9     0.9     0.9       0          2.5\n",
      "7     Hoefler   0.8   0.7       0     0.8     0.7       0          2.3\n",
      "8    Horigome   0.8   0.9     1.0     0.9     0.8       0          2.8\n",
      "9      Huston   0.6   0.9       0     0.9       0     0.9          2.7\n",
      "10     Jordan   0.8   0.8     0.9     0.9     0.8       0          2.6\n",
      "11     Joslin   0.8   0.7     0.9     0.8       0     0.9          2.6\n",
      "12    Majerus   0.5   0.2       0     0.9     0.5     0.7          2.1\n",
      "13    McClung   0.3   0.3       0       0     0.3       0          0.6\n",
      "14     Midler   0.6   0.6       0       0       0       0          0.6\n",
      "15      Milou   0.7   0.7     0.8       0       0       0          1.5\n",
      "16       Mota   0.6   0.5     0.9     0.8       0       0          2.3\n",
      "17   Oliveira   0.4   0.5     0.8       0       0       0          1.3\n",
      "18    Oâ€™neill   0.5   0.4       0       0     0.8       0          1.3\n",
      "19       Papa   0.4   0.5       0       0     0.8     0.8          2.1\n",
      "20    Pudwill   0.4   0.2       0     0.6     0.6     0.6          1.6\n",
      "21  Ribeiro C   0.3   0.5       0       0       0       0          0.5\n",
      "22  Ribeiro G   0.8   0.8     0.9       0       0     0.9          2.6\n",
      "23  Rodriguez   0.7   0.5       0     0.8       0     0.8          2.3\n",
      "24   Santiago   0.1   0.2       0       0     0.7       0          0.9\n",
      "25     Shirai   0.4   0.9     0.9       0       0       0          1.8\n",
      "26     Silvas   0.2   0.4     0.8     0.8       0       0          2.0\n",
      "27      Suciu   0.7   0.3     0.7       0     0.9     0.8          2.4\n",
      "28       Wair   0.6   0.8     0.7       0       0     0.8          2.3\n",
      "29     Wright   0.3   0.3     0.6       0     0.6       0          1.5\n"
     ]
    }
   ],
   "source": [
    "print(simulate_lcq(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_four_skateboarders(new_lcq_df):\n",
    "    return sort_my_df(new_lcq_df).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  win_count\n",
      "7    Horigome       1559\n",
      "0   Ribeiro G        751\n",
      "4      Shirai        634\n",
      "1      Huston        561\n",
      "2      Jordan        424\n",
      "6       Milou        356\n",
      "8       Hoban        271\n",
      "5      Joslin         76\n",
      "13    Decenzo         70\n",
      "16    Gustavo         57\n",
      "9     Hoefler         56\n",
      "10       Wair         50\n",
      "12      Suciu         42\n",
      "14    Oâ€™neill         27\n",
      "3         Foy         23\n",
      "17       Fynn         15\n",
      "11       Papa         12\n",
      "15      Eaton          8\n",
      "19  Ribeiro C          3\n",
      "21   Oliveira          3\n",
      "18  Rodriguez          1\n",
      "20       Mota          1\n"
     ]
    }
   ],
   "source": [
    "win_counts = {}\n",
    "\n",
    "for _ in range(5000):\n",
    "    top_four_df=find_top_four_skateboarders(simulate_lcq(results_df))\n",
    "    winner_id = top_four_df.iloc[0]['id']\n",
    "    win_counts[winner_id] = win_counts.get(winner_id, 0) + 1\n",
    "    \n",
    "df_win_counts = pd.DataFrame(list(win_counts.items()), columns=['id', 'win_count'])\n",
    "df_ranked = df_win_counts.sort_values(by='win_count', ascending=False)\n",
    "\n",
    "print(df_ranked)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bayesian Model\n",
    "\n",
    "As an alternative to the frequentist model developed in Task 2, we can consider a Bayesian model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) \n",
    "Propose a joint prior distribution for the parameters $[\\Theta_i, A_i, B_i]^T$ for $X_i$ where we assume $\\Theta_i \\perp A_i, B_i$ for all $i$. \n",
    "\n",
    "- Justify your choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "Generate 5000 random samples from the posterior distribution\n",
    "$$\n",
    "f_{\\theta_i, \\alpha_i, \\beta_i | \\boldsymbol{X}_i}(\\theta_i, \\alpha_i, \\beta_i | \\boldsymbol{x}_i) .\n",
    "$$\n",
    "Plot your resulting samples for the marginal posterior distributions:\n",
    "$$\n",
    "f_{\\theta_i | \\boldsymbol{X}_i}(\\theta_i | \\boldsymbol{x}_i) \\quad \\text{and} \\quad f_{\\alpha_i, \\beta_i | \\boldsymbol{X}_i}(\\alpha_i, \\beta_i | \\boldsymbol{x}_i) .\n",
    "$$\n",
    "Calculate the posterior sample mean and the posterior sample variance for each parameter $ \\theta_i, \\alpha_i $, and $ \\beta_i $ for all skateboarders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) \n",
    "- Propose a (joint) prior distribution for the parameters of your model $Y_i$ from task $2(c)$ and justify your choice. \n",
    "\n",
    "- You can assume that the model's parameters for skateboarder $i$ are independent of all other parameters including $\\theta_i$, $\\alpha_i$, and $\\beta_i$. \n",
    "\n",
    "- Generate 5000 samples from the posterior distribution (make sure to save these samples!) and create a scatter plot of the results. \n",
    "\n",
    "- What is the sample mean and sample variance for each of your parameters based on your outcomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) \n",
    "Use your Bayesian model for $[X_i, Y_i]^T$ to simulate 5000 LCQs by drawing samples from the appropriate posterior predictive distributions. \n",
    "\n",
    "- What is the mode of your outcomes $W_1, \\ldots, W_{5000}$? \n",
    "\n",
    "- How many of the real winners are predicted? \n",
    "\n",
    "- What is the estimated probability of the real winners based on your samples? \n",
    "\n",
    "- And by the mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) \n",
    "In the model in task $3(\\mathrm{d})$, we assumed that the parameters $\\Upsilon_i$ for $Y_i$ and the parameters $\\Theta_i = [\\Theta_i, A_i, B_i]^T$ for $X_i$ are independent given the data. \n",
    "\n",
    "- Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, we did not assume that $\\Theta_i \\perp A_i, B_i$ are independent given the data. \n",
    "\n",
    "1. Let $X_i^{(1)}, X_i^{(2)}, X_i^{(3)}, X_i^{(4)}$ denote skateboarder $i$'s four trick scores.\n",
    "2. Let $Y_i^{(1)}, Y_i^{(2)}$ denote skateboarder $i$'s two run scores.\n",
    "3. Let $O_i$ denote their total score. \n",
    "\n",
    "- Draw a directed acyclic graph with as few edges as possible so that the joint distribution of $O_i, X_i^{(1)}, X_i^{(2)}, X_i^{(3)}, X_i^{(4)}, Y_i^{(1)}, Y_i^{(2)}, \\Theta_i, A_i, B_i$ and $\\Upsilon$ is Markov with respect to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Based on your graph, can you conclude that the marginal posterior distribution for $\\Theta_i, A_i$, and $B_i$ factorizes as:\n",
    "$$\n",
    "f_{\\theta_i, \\alpha_i, \\beta_i | \\boldsymbol{X}_i}(\\theta_i, \\alpha_i, \\beta_i | \\boldsymbol{x}_i) = f_{\\theta_i | \\boldsymbol{X}_i}(\\theta_i | \\boldsymbol{x}_i) f_{\\alpha_i, \\beta_i | \\boldsymbol{X}_i}(\\alpha_i, \\beta_i | \\boldsymbol{x}_i) ?\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider your parameters $\\Upsilon_i$ for $Y_i$ and the parameters $\\Theta_i$ for $X_i$. \n",
    "\n",
    "- According to your graph, is the following assumption reasonable?\n",
    "\n",
    "$$\n",
    "\\Upsilon_i \\perp \\Theta_i | X_i^{(1)}, X_i^{(2)}, X_i^{(3)}, X_i^{(4)}, Y_i^{(1)}, Y_i^{(2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can we assume the independence relation $\\Upsilon_i \\perp \\Theta_i | O_i$ if only the data $o_i$ is given instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. A Bayesian model with a hierarchy\n",
    "To account for possible variations in skateboarders' performances between different competitions, we can build a model that uses a hierarchy. As we saw in the lectures, we can build a Bayesian hierarchy for $V_i \\sim \\operatorname{Ber}(\\theta_i)$ if we group outcomes $v_i$ according to the different competitions. For simplicity, we use our frequentist point estimates for the parameters $\\alpha_i, \\beta_i$ and the parameters for $Y_i$ from task 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) \n",
    "Assume that $\\Theta_i \\mid A_i=\\alpha_i, B_i=\\beta_i \\sim \\operatorname{Beta}(\\alpha_i, \\beta_i)$ and choose a suitable simultaneous prior distribution for $\\left[\\Theta_i, A_i, B_i\\right]^T$. \n",
    "\n",
    "- Justify your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "\n",
    "Generate 5000 random outcomes from the simultaneous posterior distribution\n",
    "$$\n",
    "f_{A_i, B_i \\mid \\boldsymbol{X}_i}(a_i, b_i \\mid \\boldsymbol{x}_i) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your simulations to generate 5000 random outcomes from the marginal posterior distribution $\\Theta_i \\mid \\boldsymbol{X}_i=\\boldsymbol{x}_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your outcomes for the following posterior distributions:\n",
    "$$\n",
    "f_{\\theta_i \\mid \\boldsymbol{X}_i}(\\theta_i \\mid \\boldsymbol{x}_i) \\quad \\text{and} \\quad f_{A_i, B_i \\mid \\boldsymbol{X}_i}(a_i, b_i \\mid \\boldsymbol{x}_i) ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide estimates for the posterior expected value and posterior variance for each of the parameters. \n",
    "\n",
    "- How do these variances for $\\theta_i$ compare to the variances for $\\theta_i$ computed for the model in Task 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) \n",
    "Using your $5000$ samples from part (b), simulate 5000 LCQ competition winners and calculate the mode of the results. \n",
    "\n",
    "- What are the respective estimated probabilities for the actual winners and your mode value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Discussion \n",
    "It is always important to reflect on our model assumptions when conducting statistical inference. Specifically, it is important to assess how the models can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) \n",
    "\n",
    "- How do the results (the skateboarders in the typical values) from the different models compare? \n",
    "\n",
    "- Which skateboarders are correctly predicted and which are not? \n",
    "\n",
    "- Provide some possible explanations for the differences between the predictions of the different models. \n",
    "\n",
    "- Which model do you prefer and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "\n",
    "- How do your estimates for $\\theta_i$ in Assignment 1 compare to your estimated expected values and variances for $\\theta_i$ in Assignments 3 and 4? \n",
    "\n",
    "- What is the expected score for a trick for each skateboarder given that the trick has been successfully landed? What is the expected run score? \n",
    "\n",
    "- Considering the skateboarders who are predicted to win according to the different models, do these statistics provide any insights into successful strategies for winning? \n",
    "\n",
    "- For example, does it work to focus on a good run score over good trick scores? \n",
    "\n",
    "- Are there instances where this strategy works? \n",
    "\n",
    "- Is it better to have higher trick scores with high variance or slightly worse trick scores with less variance? etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) \n",
    "\n",
    "- Estimate the expected value and standard deviation for each skateboarder's total score for the models in Assignments 3 and 4. \n",
    "\n",
    "- Do these statistics support your predictions? \n",
    "\n",
    "- According to these statistics, what needs to occur for the outcome to be the actual winners?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) \n",
    "\n",
    "- In all the models, we assumed that the skateboarder's performances are independent. For example, we assumed that all $V_i$ are independent. \n",
    "\n",
    "- Does this seem like a reasonable assumption? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) \n",
    "\n",
    "- In all the models, we ignored the order in which the skateboarders took turns. Does this seem like a reasonable thing to do? \n",
    "\n",
    "- Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
