We'd like to construct a model that can predict which of the 16 skateboarders in the LCQ will secure a spot in the final. 
One approach to this is to construct a model for each skateboarder, utilize these models to simulate run scores and trick scores for every skateboarder, and then combine these simulations to simulate the LCQ as a whole. 
By simulating multiple LCQs, we can extract the top four skateboarders with the highest cumulative scores from each. 
Our prediction would then be the mode of these outcomes. 
**NOTE:** *Please note that this model assumes that the performances of the skateboarders are independent. For the sake of simplicity, we'll assume that the score for a particular run $Y_i$ and the score for a specific trick $X_i$ are independent for each skateboarder.*
- For skateboarder $i$, we assume that all trick scores and run scores are independent and have identically distributed outcomes from $X_i$ and $Y_i$ respectively. 
- We can start by specifying a model for $X_i$ and $Y_i$. 
From the observations in Task 1, a plausible model for $X_i$ is the following:
$$
X_i = 
\begin{cases} 
0 & \text{if } V_i = 0, \\ 
Z_i & \text{if } V_i = 1,
\end{cases}
$$
where 
$$ V_i \sim \text{Ber}(\theta_i), $$
$$ Z_i \sim \text{Beta}(\alpha_i, \beta_i) $$
and 
$$ V_i \perp Z_i. $$
It can be shown that
$$ 
f_{X_i}(x_i | \theta_i, \alpha_i, \beta_i) = (1-\theta_i) \mathbb{1}_{\{x_i=0\}} + \theta_i f_{Z_i}(z_i).
$$
The choice $ V_i \sim \text{Ber}(\theta_i) $ models the fact that a skateboarder receives a score of 0 if and only if they do not successfully land the trick. Meanwhile, the choice $ Z_i \sim \text{Beta}(\alpha_i, \beta_i) $ models that the score for a particular trick represents the portion of the trick that was "perfect."
## (a) Provide a point estimate for each $\theta_i$
# Extracting data and calculating the mean for each skateboarder at each location.
make_columns = ['make 1', 'make 2', 'make 3', 'make 4']
df['total_made'] = df[make_columns].sum(axis=1)
df['total_attempted'] = df[['trick 1', 'trick 2', 'trick 3', 'trick 4']].notna().sum(axis=1)
df['theta_i'] = df['total_made'] / df['total_attempted']
# Group by 'id' and compute the mean of theta_i for each skateboarder
theta_average = df.groupby('id')['theta_i'].mean().reset_index()
# Rename the columns for clarity
theta_average.columns = ['id', 'theta_average']
#Okay, that's great! 
# Now I have this information, but I would like to save it into the main DataFrame file.
# Merge the theta_average DataFrame with the original df on 'id'
df = df.merge(theta_average, on='id', how='left')
## (b) Provide a point estimate for the parameters $\left[\alpha_i, \beta_i\right]^{\mathrm{T}}$ for each skateboarder $i$. 
For the Beta distribution:
$$
f\left(z_i \mid \alpha_i, \beta_i\right)=\frac{z_i^{\alpha_i-1}\left(1-z_i\right)^{\beta_i-1}}{B\left(\alpha_i, \beta_i\right)}
$$
where $B\left(\alpha_i, \beta_i\right)$ is the beta function, which acts as a normalization constant.

From the provided data, we have scores for each trick when it's not zero. 
To estimate $\alpha_i$ and $\beta_i$, we can make use of the mean and variance properties of the Beta distribution.

To the population mean and variance, we knwo from formula sheet:

- Mean: $\mu=\frac{\alpha_i}{\alpha_i+\beta_i}$
- Variance: $\sigma^2=\frac{\alpha_i \beta_i}{\left(\alpha_i+\beta_i\right)^2\left(\alpha_i+\beta_i+1\right)}$

$$
\mu = \frac{\alpha}{\alpha+\beta} \quad \text { and } \quad S^2 = \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)} .
$$
Solving for $\alpha$ and $\beta$:
$$
\beta = \frac{\alpha - \alpha \mu}{\mu} = \frac{\alpha}{\mu} - \alpha .
$$
After substituting and simplifying, we find:
$$
\alpha = \mu\left(\frac{\mu(1-\mu)}{S^2}-1\right) .
$$
Expressing $\beta$ using $\mu$ and $S^2$:
$$
\beta = (1-\mu)\left(\frac{\mu(1-\mu)}{S^2}-1\right) .
$$
We can derive the method of moment estimators for $\alpha$ and $\beta$ are:
$$
\hat{\alpha} = \mu\left(\frac{\mu(1-\mu)}{S^2}-1\right) \text { and } \hat{\beta} = (1-\mu)\left(\frac{\mu(1-\mu)}{S^2}-1\right)
$$
trick_columns = ['trick 1', 'trick 2', 'trick 3', 'trick 4']
# Group by 'id' and aggregate tricks for each skateboarder
all_tricks_df_with_zeroes = df.melt(id_vars='id', value_vars=trick_columns)\
                  .groupby('id')['value']\
                  .apply(list)\
                  .reset_index()
# Rename the columns for clarity
all_tricks_df_with_zeroes.columns = ['id', 'tricks']
# Uncoment this to see the results.
all_tricks_df_with_zeroes
def get_moment_estimators(data):
    moment_estimators = []
    # I want to handel if I have only 1 datpoint.
    if len(data) == 1:
        mean = data[0]
        global_trick_data = sum(all_tricks_df['tricks'].tolist(), [])
        variance = np.var(global_trick_data, ddof=1)
    else:
        # Calculate mean
        mean = np.mean(data)
        
        # Calculate variance
        # ddof=1 means that we want to calculate the sample variance
        variance = np.var(data, ddof=1)
    #-----------------------------------
    # Calculate a1
    a1 = mean * (mean * (1 - mean) / variance - 1)
    moment_estimators.append(a1)
    # Calculate b1
    b1 = (1 - mean) * (mean * (1 - mean) / variance - 1)
    moment_estimators.append(b1)
    return moment_estimators
for index, row in Moment_Estimators_results_alpha_beta_df.iterrows():
    samps = np.array(row['tricks'])
    
    alpha_beta = get_moment_estimators(samps)
   
    Moment_Estimators_results_alpha_beta_df.at[index, 'alpha_trick'] = round(alpha_beta[0],2)
    Moment_Estimators_results_alpha_beta_df.at[index, 'beta_trick'] = round(alpha_beta[1],2)
results_df_Moment_Estimators = results_df.copy()
results_df_Moment_Estimators['alpha_trick'] = Moment_Estimators_results_alpha_beta_df['alpha_trick']
results_df_Moment_Estimators['beta_trick'] = Moment_Estimators_results_alpha_beta_df['beta_trick']
results_df_Moment_Estimators
id	theta_average	alpha_trick	beta_trick
0	Decenzo	0.437500	20.84	4.36
1	Eaton	0.625000	60.17	15.99
2	Foy	0.500000	42.85	7.56
3	Gustavo	0.400000	61.71	15.31
4	Hoban	0.400000	94.13	13.14
5	Hoefler	0.437500	27.77	8.03
6	Jordan	0.400000	20.07	3.17
7	Majerus	0.375000	1.77	1.66
8	Midler	0.333333	32.59	7.77
9	Mota	0.250000	15.74	4.44
10	Oliveira	0.416667	54.94	14.26
11	Oâ€™neill	0.250000	834.83	155.09
12	Papa	0.437500	19.02	5.41
13	Ribeiro C	0.250000	129.59	37.27
14	Santiago	0.083333	10.64	12.00
15	Shirai	0.400000	17.90	2.04
## (c) Propose a model for $Y_i$ and provide a point estimate for the parameters of your model. 
#Create all runs.
def aggregate_runs(runs):
    # This function aggregates the runs by filtering out zero values
    return list(runs[runs != 0])
# Assuming the runs are stored in columns named 'run1', 'run2', 'run3', etc.
run_columns = ['run 1', 'run 2']  # Add more columns if needed

# Group by 'id' and aggregate runs for each skateboarder
all_runs_df = df.melt(id_vars='id', value_vars=run_columns)\
                  .groupby('id')['value']\
                  .agg(aggregate_runs)\
                  .reset_index()

# Rename the columns for clarity
all_runs_df.columns = ['id', 'runs']
# Uncoment this to see the results.
all_runs_df
Method_Moment_results_alpha_beta_df_runs = all_runs_df.copy()
for index, row in Method_Moment_results_alpha_beta_df_runs.iterrows():
    samps = np.array(row['runs'])
    
    alpha_beta = get_moment_estimators(samps)
    
    Method_Moment_results_alpha_beta_df_runs.at[index, 'alpha_run'] = round(alpha_beta[0],2)
    Method_Moment_results_alpha_beta_df_runs.at[index, 'beta_run'] = round(alpha_beta[1],2)
results_df_Moment_Estimators['alpha_run'] = Method_Moment_results_alpha_beta_df_runs['alpha_run']
results_df_Moment_Estimators['beta_run'] = Method_Moment_results_alpha_beta_df_runs['beta_run']
results_df_Moment_Estimators
def successful_trick(theta):
    made=bool(np.random.binomial(1, theta))
    return made
def trick_score(alpha, beta):
    return stats.beta.rvs(alpha, beta, size=1)[0]
def run_score(alpha, beta):
    return stats.beta.rvs(alpha, beta, size=1)[0]
ef total_score(trick_scores, run_scores):
    return max(run_scores) + sorted(trick_scores)[-1] + sorted(trick_scores)[-2]
def sort_my_df(new_lcq_df):
    sorted_df = new_lcq_df.sort_values(by='total score', ascending=False)
    return sorted_df
def simulate_lcq(chosen_results_df):
    new_lcq_df = pd.DataFrame(columns=["id", "run 1", "run 2", "trick 1", "trick 2", "trick 3", "trick 4"])
    
    for index, row in chosen_results_df.iterrows():
        
        theta_average=row['theta_average']
        alpha_trick=row['alpha_trick']
        beta_trick=row['beta_trick']    
        alpha_run=row['alpha_run']
        beta_run=row['beta_run']
        
        new_lcq_df.at[index, "id"]=row['id']
        
        for _ in range(4):
            if successful_trick(theta_average):
                trick=trick_score(alpha_trick, beta_trick)
            else:
                trick=0
            new_lcq_df.at[index, f"trick {_+1}"] = round(trick,1)
        
        for _ in range(2):
            run=run_score(alpha_run, beta_run)
            new_lcq_df.at[index, f"run {_+1}"] = round(run,1)
        
        total_score_value=total_score(new_lcq_df.loc[index, ['trick 1', 'trick 2', 'trick 3', 'trick 4']], new_lcq_df.loc[index, ['run 1', 'run 2']]) 
        new_lcq_df.at[index, "total score"]=round(total_score_value,1)
    
    return new_lcq_df
def find_top_four_skateboarders(new_lcq_df):
    return sort_my_df(new_lcq_df).head(4)
def find_mode_and_occurences_of_specific(data, specific):
    dict = {}
    for winners in data:
        winner_vector = tuple(sorted(winners))
        if winner_vector in dict.keys():
            dict[winner_vector] += 1
        else:
            dict[winner_vector] = 1
    mode = max(dict, key=dict.get)
    count = dict[mode]
    print(f"Mode: {mode}, count {count}")
    count_of_specific = dict.get(tuple(sorted(specific)), 0)
    print(f"Estimated probability for specific: {count_of_specific/5000}")
# For each method (Moment Estimators, Gradient Descent, Newton Raphson)
methods = ['Moment_Estimators', 'Gradient_Descent', 'Newton_Raphson']
dataframes = [results_df_Moment_Estimators, results_df_Gradient_Descent, results_df_Newton_Raphson]

dfs_ranked = {}  # Store the resulting DataFrames

for method, df in zip(methods, dataframes):
    top_four_rankings = []
    point_counts = {}

    for _ in range(5000):
        lcq_results = simulate_lcq(df)
        top_four_df = find_top_four_skateboarders(lcq_results)
        
        # Extract IDs of the top four skateboarders
        top_four_ids = top_four_df['id'].tolist()[:4]
        top_four_rankings.append(top_four_ids)
        
        # Loop through the top 4 skateboarders and award them a point
        for i in range(4):
            skateboarder_id = top_four_df.iloc[i]['id']
            point_counts[skateboarder_id] = point_counts.get(skateboarder_id, 0) + 1

    print(f"\n\nFor {method}:")
    find_mode_and_occurences_of_specific(top_four_rankings, ["Gustavo", "Decenzo", "Eaton", "Hoban"])
    
    # Convert the point_counts dictionary to a DataFrame and rank the skateboarders
    df_ranked = pd.DataFrame(list(point_counts.items()), columns=['id', 'points'])
    df_ranked = df_ranked.sort_values(by='points', ascending=False)
    df_ranked['rank'] = df_ranked['points'].rank(ascending=False)
    
    dfs_ranked[method] = df_ranked  # Store the DataFrame in a dictionary
